# AME æ¶æ„ä¼˜åŒ–è®¾è®¡æ–‡æ¡£

## 1. æ¦‚è¿°

### 1.1 é¡¹ç›®å®šä½

**AME (Another-Me Engine)** æ˜¯çº¯ç®—æ³•èƒ½åŠ›å±‚ï¼Œä¸“æ³¨æä¾›ï¼š
- ğŸ” æ··åˆæ£€ç´¢ç®—æ³•ï¼ˆPipeline æ¶æ„ï¼‰
- ğŸ§  NER å®ä½“è¯†åˆ«ç®—æ³•ï¼ˆCascade Inference æ¡†æ¶ï¼‰
- ğŸ“Š æ•°æ®åˆ†æç®—æ³•
- ğŸ­ é£æ ¼æ¨¡ä»¿ç®—æ³•
- ğŸ’¾ æ•°æ®å¤„ç†ç®—æ³•

**æ˜ç¡®è¾¹ç•Œ**ï¼š
- âœ… åŒ…æ‹¬ï¼šç®—æ³•å®ç°ã€æ•°æ®å¤„ç†ã€æ¨¡å‹è°ƒç”¨
- âŒ ä¸åŒ…æ‹¬ï¼šREST APIã€HTTP è·¯ç”±ã€ä¸šåŠ¡ç¼–æ’

### 1.2 ä¼˜åŒ–ç›®æ ‡

| ç»´åº¦ | å½“å‰é—®é¢˜ | ä¼˜åŒ–ç›®æ ‡ |
|------|---------|---------|
| **æ¶æ„** | æ¨¡å—ç¢ç‰‡åŒ–ã€èŒè´£é‡å  | ç»Ÿä¸€æ¡†æ¶ã€æ¸…æ™°æŠ½è±¡ |
| **æ€§èƒ½** | LLM æˆæœ¬é«˜ã€å“åº”æ…¢ | æˆæœ¬é™ä½ 60-70%ã€é€Ÿåº¦æå‡ 3-5å€ |
| **å‡†ç¡®ç‡** | å›ºå®šæƒé‡ã€ç¼ºä¹è‡ªé€‚åº” | å‡†ç¡®ç‡æå‡ 15-25% |
| **å¯ç»´æŠ¤æ€§** | é‡å¤ä»£ç ã€ç´§è€¦åˆ | ä»£ç å¤ç”¨æå‡ 70% |

### 1.3 ä¼˜åŒ–åŸåˆ™

1. **æ¶æ„å…ˆè¡Œ**ï¼šå…ˆç»Ÿä¸€æ¡†æ¶ï¼Œå†ä¼˜åŒ–ç®—æ³•ç»†èŠ‚
2. **å‘å‰å…¼å®¹**ï¼šé¡¹ç›®é‡æ„ä¸­ï¼Œæ— éœ€è€ƒè™‘å‘åå…¼å®¹
3. **æ¨¡å—ç‹¬ç«‹**ï¼šæ¯ä¸ªæ¨¡å—å¯ç‹¬ç«‹æµ‹è¯•å’Œæ›¿æ¢
4. **æˆæœ¬ä¼˜å…ˆ**ï¼šå¤šå±‚çº§æ¨ç†é™ä½ LLM è°ƒç”¨é¢‘ç‡

---

## 2. æ¶æ„ä¼˜åŒ–

### 2.1 æ£€ç´¢æ¨¡å—ï¼šPipeline æ¶æ„

#### 2.1.1 ç°çŠ¶é—®é¢˜

**å½“å‰æ¶æ„**ï¼š
```
retrieval/
â”œâ”€â”€ vector_retriever.py    # å‘é‡æ£€ç´¢
â”œâ”€â”€ graph_retriever.py     # å›¾è°±æ£€ç´¢
â”œâ”€â”€ hybrid_retriever.py    # æ··åˆæ£€ç´¢ï¼ˆç»„åˆå™¨ï¼‰
â””â”€â”€ reranker.py            # é‡æ’åºï¼ˆå¦ä¸€ä¸ªç»„åˆå™¨ï¼‰
```

**æ ¸å¿ƒé—®é¢˜**ï¼š
- âŒ `hybrid_retriever` å’Œ `reranker` èŒè´£é‡å ï¼Œéƒ½æ˜¯ç»„åˆå™¨
- âŒ éš¾ä»¥çµæ´»ç»„åˆç­–ç•¥ï¼ˆå¦‚ï¼šå‘é‡ + å›¾è°± + æ„å›¾è‡ªé€‚åº” + é‡æ’åº + å¤šæ ·æ€§è¿‡æ»¤ï¼‰
- âŒ æ–°å¢æ£€ç´¢ç­–ç•¥éœ€ä¿®æ”¹å¤šå¤„ä»£ç ï¼Œè¿åå¼€æ”¾-å°é—­åŸåˆ™

#### 2.1.2 ä¼˜åŒ–æ–¹æ¡ˆ

**ç›®æ ‡æ¶æ„**ï¼šç»Ÿä¸€ä¸º **Pipeline æ¶æ„**ï¼ˆè´£ä»»é“¾æ¨¡å¼ + ç­–ç•¥æ¨¡å¼ï¼‰

```
retrieval/
â”œâ”€â”€ base.py                     # åŸºç¡€æ¥å£
â”œâ”€â”€ pipeline.py                 # ğŸ†• Pipeline æ ¸å¿ƒå¼•æ“
â”œâ”€â”€ stages/                     # ğŸ†• æ£€ç´¢é˜¶æ®µï¼ˆå¯ç»„åˆï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                 # Stage æŠ½è±¡åŸºç±»
â”‚   â”œâ”€â”€ vector_stage.py         # å‘é‡å¬å›é˜¶æ®µ
â”‚   â”œâ”€â”€ graph_stage.py          # å›¾è°±å¬å›é˜¶æ®µ
â”‚   â”œâ”€â”€ fusion_stage.py         # èåˆé˜¶æ®µ
â”‚   â”œâ”€â”€ rerank_stage.py         # é‡æ’åºé˜¶æ®µ
â”‚   â”œâ”€â”€ diversity_stage.py      # å¤šæ ·æ€§è¿‡æ»¤é˜¶æ®µ
â”‚   â””â”€â”€ intent_adaptive_stage.py # æ„å›¾è‡ªé€‚åº”é˜¶æ®µ
â””â”€â”€ factory.py                  # Pipeline å·¥å‚
```

#### 2.1.3 æ ¸å¿ƒç±»è®¾è®¡

##### Pipeline æ ¸å¿ƒå¼•æ“

```python
# retrieval/pipeline.py
class RetrievalPipeline:
    """æ£€ç´¢ç®¡é“ï¼šæ”¯æŒå¤šé˜¶æ®µç»„åˆ
    
    è®¾è®¡æ¨¡å¼ï¼šè´£ä»»é“¾æ¨¡å¼
    æ ¸å¿ƒä¼˜åŠ¿ï¼š
    1. å¯ç»„åˆæ€§ï¼šä»»æ„ç»„åˆæ£€ç´¢é˜¶æ®µ
    2. å¯æ‰©å±•æ€§ï¼šæ–°å¢é˜¶æ®µæ— éœ€ä¿®æ”¹ç°æœ‰ä»£ç 
    3. å¯æµ‹è¯•æ€§ï¼šæ¯ä¸ªé˜¶æ®µç‹¬ç«‹æµ‹è¯•
    """
    
    def __init__(self):
        self.stages: List[StageBase] = []
    
    def add_stage(self, stage: StageBase) -> 'RetrievalPipeline':
        """æ·»åŠ æ£€ç´¢é˜¶æ®µï¼ˆæ”¯æŒé“¾å¼è°ƒç”¨ï¼‰"""
        self.stages.append(stage)
        return self
    
    async def execute(
        self, 
        query: str, 
        top_k: int = 10,
        context: Optional[Dict] = None
    ) -> List[RetrievalResult]:
        """æ‰§è¡Œæ£€ç´¢ç®¡é“
        
        æµç¨‹ï¼š
        1. åˆå§‹åŒ–ä¸Šä¸‹æ–‡ï¼ˆå…±äº«æŸ¥è¯¢ã€å‚æ•°ï¼‰
        2. é¡ºåºæ‰§è¡Œå„é˜¶æ®µ
        3. æ¯é˜¶æ®µæ¥æ”¶å‰åºç»“æœï¼Œè¾“å‡ºæ–°ç»“æœ
        4. è¿”å›æœ€ç»ˆ top_k ç»“æœ
        """
        results = None
        ctx = context or {}
        ctx.update({"query": query, "top_k": top_k})
        
        for stage in self.stages:
            results = await stage.process(query, results, ctx)
        
        return results[:top_k] if results else []
```

##### Stage æŠ½è±¡åŸºç±»

```python
# retrieval/stages/base.py
class StageBase(ABC):
    """æ£€ç´¢é˜¶æ®µæŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    async def process(
        self,
        query: str,
        previous_results: Optional[List[RetrievalResult]],
        context: Dict[str, Any]
    ) -> List[RetrievalResult]:
        """å¤„ç†æ£€ç´¢é˜¶æ®µ
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            previous_results: å‰åºé˜¶æ®µç»“æœï¼ˆNone è¡¨ç¤ºé¦–é˜¶æ®µï¼‰
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå…±äº«æ•°æ®ï¼‰
        
        Returns:
            å½“å‰é˜¶æ®µè¾“å‡ºç»“æœ
        """
        pass
    
    @abstractmethod
    def get_name(self) -> str:
        """é˜¶æ®µåç§°"""
        pass
```

##### å‘é‡å¬å›é˜¶æ®µ

```python
# retrieval/stages/vector_stage.py
class VectorRetrievalStage(StageBase):
    """å‘é‡å¬å›é˜¶æ®µ
    
    èŒè´£ï¼š
    1. å‘é‡åŒ–æŸ¥è¯¢
    2. Faiss æ£€ç´¢
    3. è¿”å›å€™é€‰é›†ï¼ˆé€šå¸¸ top_k * 2ï¼‰
    """
    
    def __init__(self, vector_retriever: VectorRetriever, weight: float = 1.0):
        self.retriever = vector_retriever
        self.weight = weight
    
    async def process(
        self,
        query: str,
        previous_results: Optional[List[RetrievalResult]],
        context: Dict[str, Any]
    ) -> List[RetrievalResult]:
        top_k = context.get("top_k", 10)
        
        # å¬å›æ›´å¤šç”¨äºåç»­èåˆ
        results = await self.retriever.retrieve(query, top_k=top_k * 2)
        
        # åº”ç”¨æƒé‡
        for r in results:
            r.score *= self.weight
            r.metadata["stage"] = self.get_name()
        
        return results
    
    def get_name(self) -> str:
        return "VectorRetrieval"
```

##### èåˆé˜¶æ®µ

```python
# retrieval/stages/fusion_stage.py
class FusionStage(StageBase):
    """èåˆé˜¶æ®µ
    
    èŒè´£ï¼š
    1. åˆå¹¶å¤šæºç»“æœï¼ˆå‘é‡ + å›¾è°±ï¼‰
    2. æŒ‰ doc_id å»é‡
    3. åˆ†æ•°èåˆï¼ˆåŠ æƒæ±‚å’Œï¼‰
    """
    
    def __init__(self, fusion_method: str = "weighted_sum"):
        self.fusion_method = fusion_method
    
    async def process(
        self,
        query: str,
        previous_results: Optional[List[RetrievalResult]],
        context: Dict[str, Any]
    ) -> List[RetrievalResult]:
        if not previous_results:
            return []
        
        # æŒ‰ doc_id èšåˆ
        score_map = defaultdict(lambda: {"score": 0.0, "result": None})
        
        for result in previous_results:
            doc_id = result.metadata.get("doc_id")
            score_map[doc_id]["score"] += result.score
            if score_map[doc_id]["result"] is None:
                score_map[doc_id]["result"] = result
        
        # æ„å»ºèåˆç»“æœ
        fused = []
        for doc_id, data in score_map.items():
            result = data["result"]
            result.score = data["score"]
            result.metadata["fusion_method"] = self.fusion_method
            fused.append(result)
        
        # æ’åº
        fused.sort(key=lambda x: x.score, reverse=True)
        return fused
    
    def get_name(self) -> str:
        return "Fusion"
```

##### æ„å›¾è‡ªé€‚åº”é˜¶æ®µ

```python
# retrieval/stages/intent_adaptive_stage.py
class IntentAdaptiveStage(StageBase):
    """æ„å›¾è‡ªé€‚åº”é˜¶æ®µ
    
    èŒè´£ï¼š
    1. è¯†åˆ«æŸ¥è¯¢æ„å›¾ï¼ˆäº‹å®æ€§/æ—¶åºæ€§/å…³ç³»æ€§ï¼‰
    2. åŠ¨æ€è°ƒæ•´åˆ†æ•°æƒé‡
    3. ä¼˜åŒ–å¬å›è´¨é‡
    """
    
    def __init__(self, ner_extractor=None):
        self.ner = ner_extractor
    
    async def process(
        self,
        query: str,
        previous_results: Optional[List[RetrievalResult]],
        context: Dict[str, Any]
    ) -> List[RetrievalResult]:
        if not previous_results:
            return []
        
        # 1. æ„å›¾è¯†åˆ«
        intent = await self._classify_intent(query)
        
        # 2. æƒé‡è°ƒæ•´ç­–ç•¥
        adjustments = {
            "factual": {"vector": 1.2, "graph": 0.8},
            "temporal": {"vector": 1.0, "graph": 1.0},
            "relational": {"vector": 0.8, "graph": 1.2}
        }.get(intent, {"vector": 1.0, "graph": 1.0})
        
        # 3. åº”ç”¨è°ƒæ•´
        for result in previous_results:
            stage = result.metadata.get("stage", "")
            if "Vector" in stage:
                result.score *= adjustments["vector"]
            elif "Graph" in stage:
                result.score *= adjustments["graph"]
        
        # 4. é‡æ–°æ’åº
        previous_results.sort(key=lambda x: x.score, reverse=True)
        return previous_results
    
    async def _classify_intent(self, query: str) -> str:
        """æ„å›¾åˆ†ç±»
        
        è§„åˆ™ï¼š
        - äº‹å®æ€§ï¼ˆfactualï¼‰ï¼šåŒ…å« "æ˜¯ä»€ä¹ˆ"ã€"å¦‚ä½•" ç­‰
        - æ—¶åºæ€§ï¼ˆtemporalï¼‰ï¼šåŒ…å«æ—¶é—´è¯
        - å…³ç³»æ€§ï¼ˆrelationalï¼‰ï¼šåŒ…å« "å…³ç³»"ã€"è”ç³»" ç­‰
        """
        if any(kw in query for kw in ["æ˜¯ä»€ä¹ˆ", "å®šä¹‰", "å«ä¹‰"]):
            return "factual"
        if any(kw in query for kw in ["ä»€ä¹ˆæ—¶å€™", "ä½•æ—¶", "æœ€è¿‘"]):
            return "temporal"
        if any(kw in query for kw in ["å…³ç³»", "è”ç³»", "å½±å“"]):
            return "relational"
        
        # å®ä½“å¯†åº¦é«˜ â†’ å…³ç³»æ€§
        if self.ner:
            entities = await self.ner.extract(query)
            if len(entities) >= 3:
                return "relational"
        
        return "factual"
    
    def get_name(self) -> str:
        return "IntentAdaptive"
```

##### é‡æ’åºé˜¶æ®µ

```python
# retrieval/stages/rerank_stage.py
class SemanticRerankStage(StageBase):
    """è¯­ä¹‰é‡æ’åºé˜¶æ®µ
    
    èŒè´£ï¼š
    1. ä½¿ç”¨ Cross-Encoder è®¡ç®—ç²¾å‡†ç›¸å…³æ€§
    2. é‡æ–°æ’åºç»“æœ
    """
    
    def __init__(self, llm_caller=None, use_llm: bool = False):
        self.llm = llm_caller
        self.use_llm = use_llm
    
    async def process(
        self,
        query: str,
        previous_results: Optional[List[RetrievalResult]],
        context: Dict[str, Any]
    ) -> List[RetrievalResult]:
        if not previous_results or len(previous_results) <= 1:
            return previous_results
        
        if self.use_llm and self.llm:
            return await self._llm_rerank(query, previous_results)
        else:
            return await self._rule_based_rerank(query, previous_results)
    
    async def _llm_rerank(
        self, 
        query: str, 
        results: List[RetrievalResult]
    ) -> List[RetrievalResult]:
        """LLM é‡æ’åº"""
        # æ„å»º Prompt
        docs_text = "\n\n".join([
            f"æ–‡æ¡£{i}: {r.content[:200]}..."
            for i, r in enumerate(results[:10])  # é™åˆ¶æ•°é‡
        ])
        
        prompt = f"""æ ¹æ®æŸ¥è¯¢æ„å›¾ï¼Œå¯¹æ–‡æ¡£æŒ‰ç›¸å…³æ€§æ’åºã€‚

æŸ¥è¯¢ï¼š{query}

æ–‡æ¡£åˆ—è¡¨ï¼š
{docs_text}

è¯·è¿”å›æ–‡æ¡£ç¼–å·ï¼ŒæŒ‰ç›¸å…³æ€§ä»é«˜åˆ°ä½ï¼Œç”¨é€—å·åˆ†éš”ï¼š"""
        
        response = await self.llm.generate(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        
        # è§£ææ’åº
        import re
        indices = [int(n) for n in re.findall(r'\d+', response.content)]
        
        # é‡æ’åº
        reranked = [results[i] for i in indices if i < len(results)]
        remaining = [r for i, r in enumerate(results) if i not in indices]
        return reranked + remaining
    
    async def _rule_based_rerank(
        self, 
        query: str, 
        results: List[RetrievalResult]
    ) -> List[RetrievalResult]:
        """åŸºäºè§„åˆ™çš„é‡æ’åºï¼ˆå…³é”®è¯åŒ¹é…ï¼‰"""
        query_words = set(re.findall(r'\w+', query.lower()))
        
        for result in results:
            content_words = set(re.findall(r'\w+', result.content.lower()))
            overlap = len(query_words & content_words)
            
            # è°ƒæ•´åˆ†æ•°
            boost = overlap / max(len(query_words), 1) * 0.1
            result.score += boost
        
        results.sort(key=lambda x: x.score, reverse=True)
        return results
    
    def get_name(self) -> str:
        return "SemanticRerank"
```

##### å¤šæ ·æ€§è¿‡æ»¤é˜¶æ®µ

```python
# retrieval/stages/diversity_stage.py
class DiversityFilterStage(StageBase):
    """å¤šæ ·æ€§è¿‡æ»¤é˜¶æ®µ
    
    èŒè´£ï¼š
    1. ä½¿ç”¨ MMR ç®—æ³•æ§åˆ¶å¤šæ ·æ€§
    2. é¿å…ç»“æœå†—ä½™
    """
    
    def __init__(self, lambda_param: float = 0.7):
        """
        Args:
            lambda_param: ç›¸å…³æ€§æƒé‡ï¼ˆ0.0-1.0ï¼‰
                - 1.0: å®Œå…¨ç›¸å…³æ€§ä¼˜å…ˆ
                - 0.0: å®Œå…¨å¤šæ ·æ€§ä¼˜å…ˆ
                - 0.7: å¹³è¡¡ï¼ˆæ¨èï¼‰
        """
        self.lambda_param = lambda_param
    
    async def process(
        self,
        query: str,
        previous_results: Optional[List[RetrievalResult]],
        context: Dict[str, Any]
    ) -> List[RetrievalResult]:
        if not previous_results or len(previous_results) <= 1:
            return previous_results
        
        # MMR ç®—æ³•
        selected = [previous_results[0]]  # é€‰æ‹©æœ€ç›¸å…³çš„
        remaining = previous_results[1:]
        
        while remaining and len(selected) < len(previous_results):
            max_mmr = -float('inf')
            max_idx = 0
            
            for i, candidate in enumerate(remaining):
                # ç›¸å…³æ€§åˆ†æ•°
                relevance = candidate.score
                
                # ä¸å·²é€‰æ–‡æ¡£çš„æœ€å¤§ç›¸ä¼¼åº¦
                max_sim = max(
                    self._similarity(candidate, selected_doc)
                    for selected_doc in selected
                )
                
                # MMR åˆ†æ•°
                mmr = self.lambda_param * relevance - (1 - self.lambda_param) * max_sim
                
                if mmr > max_mmr:
                    max_mmr = mmr
                    max_idx = i
            
            selected.append(remaining.pop(max_idx))
        
        return selected
    
    def _similarity(self, doc1: RetrievalResult, doc2: RetrievalResult) -> float:
        """è®¡ç®—æ–‡æ¡£ç›¸ä¼¼åº¦ï¼ˆè¯é‡å ï¼‰"""
        words1 = set(re.findall(r'\w+', doc1.content.lower()))
        words2 = set(re.findall(r'\w+', doc2.content.lower()))
        
        if not words1 or not words2:
            return 0.0
        
        intersection = len(words1 & words2)
        union = len(words1 | words2)
        return intersection / union if union > 0 else 0.0
    
    def get_name(self) -> str:
        return "DiversityFilter"
```

#### 2.1.4 ä½¿ç”¨ç¤ºä¾‹

```python
# åŸºç¡€é…ç½®ï¼šå‘é‡æ£€ç´¢ + é‡æ’åº
basic_pipeline = RetrievalPipeline()
basic_pipeline\
    .add_stage(VectorRetrievalStage(vector_retriever))\
    .add_stage(SemanticRerankStage())

# é«˜çº§é…ç½®ï¼šæ··åˆæ£€ç´¢ + æ„å›¾è‡ªé€‚åº” + å¤šæ ·æ€§
advanced_pipeline = RetrievalPipeline()
advanced_pipeline\
    .add_stage(VectorRetrievalStage(vector_retriever, weight=0.6))\
    .add_stage(GraphRetrievalStage(graph_retriever, weight=0.4))\
    .add_stage(FusionStage())\
    .add_stage(IntentAdaptiveStage(ner_extractor))\
    .add_stage(SemanticRerankStage(llm_caller))\
    .add_stage(DiversityFilterStage(lambda_param=0.7))

# æ‰§è¡Œæ£€ç´¢
results = await advanced_pipeline.execute("æŸ¥è¯¢æ–‡æœ¬", top_k=10)
```

#### 2.1.5 è¿ç§»ç­–ç•¥

| ç°æœ‰æ¨¡å— | è¿ç§»æ–¹å¼ | ä¿ç•™/åˆ é™¤ |
|---------|---------|----------|
| `vector_retriever.py` | å°è£…ä¸º `VectorRetrievalStage` | ä¿ç•™ï¼ˆä½œä¸ºåº•å±‚è°ƒç”¨ï¼‰ |
| `graph_retriever.py` | å°è£…ä¸º `GraphRetrievalStage` | ä¿ç•™ï¼ˆä½œä¸ºåº•å±‚è°ƒç”¨ï¼‰ |
| `hybrid_retriever.py` | æ‹†åˆ†ä¸º `FusionStage` + `IntentAdaptiveStage` | åˆ é™¤ |
| `reranker.py` | è¿ç§»ä¸º `SemanticRerankStage` + `DiversityFilterStage` | åˆ é™¤ |

---

### 2.2 NER ä¸æƒ…ç»ªè¯†åˆ«ï¼šCascade Inference æ¡†æ¶

#### 2.2.1 ç°çŠ¶é—®é¢˜

**å½“å‰æ¶æ„**ï¼š
```
ner/
â”œâ”€â”€ simple_ner.py       # è§„åˆ™ NER
â”œâ”€â”€ llm_ner.py          # LLM NER
â””â”€â”€ hybrid_ner.py       # æ··åˆ NERï¼ˆè§„åˆ™ + LLMï¼‰

mem/
â””â”€â”€ analyze_engine.py
    â””â”€â”€ detect_emotion() # æƒ…ç»ªè¯†åˆ«ï¼ˆä¹Ÿæ˜¯è§„åˆ™ + LLMï¼‰
```

**æ ¸å¿ƒé—®é¢˜**ï¼š
- âŒ `hybrid_ner` å’Œ `detect_emotion` éƒ½ä½¿ç”¨ã€Œè§„åˆ™ â†’ LLM å…œåº•ã€ç­–ç•¥ï¼Œé€»è¾‘é‡å¤
- âŒ ç½®ä¿¡åº¦åˆ¤æ–­ã€æˆæœ¬æ§åˆ¶é€»è¾‘åˆ†æ•£åœ¨ä¸¤ä¸ªæ¨¡å—
- âŒ ç¼ºå°‘ç»Ÿä¸€çš„ã€Œå¤šå±‚çº§æ¨ç†ã€æ¡†æ¶

#### 2.2.2 ä¼˜åŒ–æ–¹æ¡ˆ

**ç›®æ ‡æ¶æ„**ï¼šæŠ½è±¡ä¸º **Cascade Inference æ¡†æ¶**ï¼ˆçº§è”æ¨ç†ï¼‰

```
core/
â””â”€â”€ cascade_inference.py    # ğŸ†• çº§è”æ¨ç†æ¡†æ¶

ner/
â”œâ”€â”€ base.py
â”œâ”€â”€ layers/                 # ğŸ†• NER æ¨ç†å±‚
â”‚   â”œâ”€â”€ rule_layer.py       # è§„åˆ™å±‚ï¼ˆAC è‡ªåŠ¨æœºï¼‰
â”‚   â”œâ”€â”€ bert_layer.py       # BERT å±‚ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰
â”‚   â””â”€â”€ llm_layer.py        # LLM å±‚ï¼ˆå…œåº•ï¼‰
â””â”€â”€ ner_engine.py           # ğŸ†• NER å¼•æ“ï¼ˆä½¿ç”¨ Cascadeï¼‰

analysis/                   # ğŸ†• åˆ†ææ¨¡å—ï¼ˆç‹¬ç«‹ï¼‰
â”œâ”€â”€ emotion/
â”‚   â”œâ”€â”€ lexicon_layer.py    # è¯å…¸å±‚
â”‚   â”œâ”€â”€ bert_layer.py       # BERT å±‚
â”‚   â””â”€â”€ llm_layer.py        # LLM å±‚
â””â”€â”€ emotion_engine.py       # æƒ…ç»ªå¼•æ“ï¼ˆä½¿ç”¨ Cascadeï¼‰
```

#### 2.2.3 æ ¸å¿ƒç±»è®¾è®¡

##### Cascade Inference æ¡†æ¶

```python
# core/cascade_inference.py
class CascadeInference:
    """çº§è”æ¨ç†æ¡†æ¶
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    1. é€å±‚å°è¯•ï¼ˆè§„åˆ™ â†’ è½»é‡æ¨¡å‹ â†’ é‡å‹æ¨¡å‹ï¼‰
    2. è¾¾åˆ°ç½®ä¿¡åº¦å³è¿”å›ï¼ŒèŠ‚çœæˆæœ¬
    3. ç»Ÿä¸€çš„ç½®ä¿¡åº¦ç®¡ç†
    
    é€‚ç”¨åœºæ™¯ï¼š
    - NER å®ä½“è¯†åˆ«
    - æƒ…ç»ªè¯†åˆ«
    - æ„å›¾åˆ†ç±»
    - æ–‡æœ¬åˆ†ç±»
    """
    
    def __init__(self):
        self.layers: List[Dict] = []
    
    def add_layer(
        self, 
        layer: InferenceLayer, 
        confidence_threshold: float = 0.7
    ) -> 'CascadeInference':
        """æ·»åŠ æ¨ç†å±‚
        
        Args:
            layer: æ¨ç†å±‚å®ä¾‹
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆè¾¾åˆ°å³è¿”å›ï¼‰
        """
        self.layers.append({
            "layer": layer,
            "threshold": confidence_threshold
        })
        return self
    
    async def infer(self, input_data: Any) -> InferenceResult:
        """æ‰§è¡Œçº§è”æ¨ç†
        
        æµç¨‹ï¼š
        1. æŒ‰é¡ºåºæ‰§è¡Œå„å±‚
        2. æ£€æŸ¥ç½®ä¿¡åº¦æ˜¯å¦è¾¾æ ‡
        3. è¾¾æ ‡å³è¿”å›ï¼Œå¦åˆ™è¿›å…¥ä¸‹ä¸€å±‚
        4. æœ€åä¸€å±‚å…œåº•ï¼ˆæ— è®ºç½®ä¿¡åº¦ï¼‰
        """
        for i, config in enumerate(self.layers):
            layer = config["layer"]
            threshold = config["threshold"]
            is_last = (i == len(self.layers) - 1)
            
            # æ‰§è¡Œæ¨ç†
            result = await layer.infer(input_data)
            
            # è®°å½•å±‚çº§ä¿¡æ¯
            result.metadata["layer"] = layer.get_name()
            result.metadata["layer_index"] = i
            
            # è¾¾åˆ°é˜ˆå€¼æˆ–æœ€åä¸€å±‚ï¼Œè¿”å›ç»“æœ
            if result.confidence >= threshold or is_last:
                return result
        
        # ç†è®ºä¸Šä¸åº”è¯¥åˆ°è¿™é‡Œ
        return InferenceResult(confidence=0.0, data=None)
```

##### æ¨ç†å±‚åŸºç±»

```python
# core/inference_layer.py
class InferenceLayer(ABC):
    """æ¨ç†å±‚æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    async def infer(self, input_data: Any) -> InferenceResult:
        """æ‰§è¡Œæ¨ç†
        
        Returns:
            InferenceResult: {
                confidence: float,  # ç½®ä¿¡åº¦ï¼ˆ0.0-1.0ï¼‰
                data: Any,          # æ¨ç†ç»“æœ
                metadata: Dict      # å…ƒæ•°æ®
            }
        """
        pass
    
    @abstractmethod
    def get_name(self) -> str:
        """å±‚çº§åç§°"""
        pass

class InferenceResult:
    """æ¨ç†ç»“æœ"""
    
    def __init__(
        self, 
        confidence: float, 
        data: Any, 
        metadata: Optional[Dict] = None
    ):
        self.confidence = confidence
        self.data = data
        self.metadata = metadata or {}
```

##### NER æ¨ç†å±‚å®ç°

```python
# ner/layers/rule_layer.py
class RuleNERLayer(InferenceLayer):
    """è§„åˆ™ NER å±‚
    
    ç‰¹æ€§ï¼š
    - é›¶æˆæœ¬ã€æ¯«ç§’çº§
    - ä½¿ç”¨ AC è‡ªåŠ¨æœºåŒ¹é…è¯å…¸
    - é«˜ç²¾åº¦ï¼ˆè¯å…¸å‡†ç¡®ï¼‰
    """
    
    def __init__(self, dictionaries: Dict[str, List[str]]):
        """
        Args:
            dictionaries: {
                "PERSON": ["å¼ ä¸‰", "æå››", ...],
                "LOCATION": ["åŒ—äº¬", "ä¸Šæµ·", ...],
                ...
            }
        """
        self.dicts = dictionaries
        # TODO: æ„å»º AC è‡ªåŠ¨æœº
    
    async def infer(self, text: str) -> InferenceResult:
        entities = []
        
        # è¯å…¸åŒ¹é…
        for entity_type, keywords in self.dicts.items():
            for keyword in keywords:
                if keyword in text:
                    entities.append(Entity(
                        text=keyword,
                        type=entity_type,
                        score=0.95  # è¯å…¸åŒ¹é…é«˜åˆ†
                    ))
        
        # ç½®ä¿¡åº¦ï¼šå®ä½“æ•°é‡ > 0 åˆ™é«˜ç½®ä¿¡åº¦
        confidence = 0.9 if entities else 0.0
        
        return InferenceResult(
            confidence=confidence,
            data=entities,
            metadata={"method": "rule", "matched": len(entities)}
        )
    
    def get_name(self) -> str:
        return "RuleNER"

# ner/layers/bert_layer.py
class BertNERLayer(InferenceLayer):
    """BERT NER å±‚
    
    ç‰¹æ€§ï¼š
    - ä½æˆæœ¬ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰
    - 100ms å†…å“åº”
    - ä¸­ç­‰å‡†ç¡®ç‡
    """
    
    def __init__(self, model_path: Optional[str] = None):
        # TODO: åŠ è½½ BERT æ¨¡å‹
        self.model = None
    
    async def infer(self, text: str) -> InferenceResult:
        if not self.model:
            return InferenceResult(confidence=0.0, data=[])
        
        # TODO: BERT æ¨ç†
        entities = []  # æ¨¡å‹è¾“å‡º
        
        # ç½®ä¿¡åº¦ï¼šæ¨¡å‹è¾“å‡ºçš„å¹³å‡åˆ†æ•°
        confidence = 0.75 if entities else 0.5
        
        return InferenceResult(
            confidence=confidence,
            data=entities,
            metadata={"method": "bert"}
        )
    
    def get_name(self) -> str:
        return "BertNER"

# ner/layers/llm_layer.py
class LLMNERLayer(InferenceLayer):
    """LLM NER å±‚
    
    ç‰¹æ€§ï¼š
    - é«˜æˆæœ¬ï¼ˆ$0.002/æ¬¡ï¼‰
    - 1-3s å“åº”
    - é«˜å‡†ç¡®ç‡
    """
    
    def __init__(self, llm_caller):
        self.llm = llm_caller
    
    async def infer(self, text: str) -> InferenceResult:
        prompt = f"""æå–æ–‡æœ¬ä¸­çš„å®ä½“ï¼š

æ–‡æœ¬ï¼š{text}

è¿”å›JSONæ ¼å¼ï¼š
[
  {{"text": "å®ä½“å", "type": "PERSON|LOCATION|ORGANIZATION|TOPIC", "score": 0.0-1.0}},
  ...
]"""
        
        response = await self.llm.generate(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        
        # è§£æ JSON
        entities = self._parse_entities(response.content)
        
        # LLM é»˜è®¤é«˜ç½®ä¿¡åº¦
        confidence = 0.95 if entities else 0.7
        
        return InferenceResult(
            confidence=confidence,
            data=entities,
            metadata={"method": "llm", "cost": 0.002}
        )
    
    def _parse_entities(self, text: str) -> List[Entity]:
        import json, re
        try:
            json_match = re.search(r'\[.*\]', text, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
                return [Entity(**item) for item in data]
        except:
            pass
        return []
    
    def get_name(self) -> str:
        return "LLMNER"
```

##### NER å¼•æ“

```python
# ner/ner_engine.py
class NEREngine:
    """NER å¼•æ“ï¼ˆä½¿ç”¨ Cascade Inferenceï¼‰"""
    
    def __init__(
        self,
        dictionaries: Dict[str, List[str]],
        llm_caller,
        use_bert: bool = False
    ):
        # æ„å»ºçº§è”æ¨ç†
        self.cascade = CascadeInference()
        
        # Layer 1: è§„åˆ™å±‚ï¼ˆå¿«é€Ÿã€é›¶æˆæœ¬ï¼‰
        self.cascade.add_layer(
            RuleNERLayer(dictionaries),
            confidence_threshold=0.9
        )
        
        # Layer 2: BERT å±‚ï¼ˆå¯é€‰ï¼Œä¸­é€Ÿã€ä½æˆæœ¬ï¼‰
        if use_bert:
            self.cascade.add_layer(
                BertNERLayer(),
                confidence_threshold=0.7
            )
        
        # Layer 3: LLM å±‚ï¼ˆå…œåº•ï¼Œæ…¢é€Ÿã€é«˜æˆæœ¬ï¼‰
        self.cascade.add_layer(
            LLMNERLayer(llm_caller),
            confidence_threshold=0.0  # å…œåº•å±‚æ— é˜ˆå€¼
        )
    
    async def extract(self, text: str) -> List[Entity]:
        """æå–å®ä½“"""
        result = await self.cascade.infer(text)
        return result.data
```

##### æƒ…ç»ªè¯†åˆ«å¼•æ“

```python
# analysis/emotion/emotion_engine.py
class EmotionEngine:
    """æƒ…ç»ªè¯†åˆ«å¼•æ“ï¼ˆä½¿ç”¨ Cascade Inferenceï¼‰"""
    
    def __init__(self, llm_caller, use_bert: bool = False):
        self.cascade = CascadeInference()
        
        # Layer 1: è¯å…¸å±‚ï¼ˆæƒ…æ„Ÿè¯å…¸ï¼‰
        self.cascade.add_layer(
            LexiconEmotionLayer(),
            confidence_threshold=0.8
        )
        
        # Layer 2: BERT å±‚ï¼ˆå¯é€‰ï¼‰
        if use_bert:
            self.cascade.add_layer(
                BertEmotionLayer(),
                confidence_threshold=0.7
            )
        
        # Layer 3: LLM å±‚ï¼ˆå…œåº•ï¼‰
        self.cascade.add_layer(
            LLMEmotionLayer(llm_caller),
            confidence_threshold=0.0
        )
    
    async def detect(self, text: str) -> Dict[str, Any]:
        """æ£€æµ‹æƒ…ç»ª"""
        result = await self.cascade.infer(text)
        return result.data
```

#### 2.2.4 æ”¶ç›Šåˆ†æ

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| **ä»£ç å¤ç”¨** | é‡å¤é€»è¾‘ | ç»Ÿä¸€æ¡†æ¶ | +70% |
| **æˆæœ¬** | 100% LLM | 30% LLMï¼ˆ70%è§„åˆ™/BERTï¼‰ | -70% |
| **é€Ÿåº¦** | 1-3s | 10ms-100msï¼ˆè§„åˆ™/BERTï¼‰ | +10-30å€ |
| **å¯æ‰©å±•æ€§** | å›°éš¾ | æ–°å¢å±‚çº§å³å¯ | é«˜ |

---

### 2.3 å­˜å‚¨å±‚ï¼šStorageAdapter ç»Ÿä¸€æ¥å£

#### 2.3.1 ç°çŠ¶é—®é¢˜

**å½“å‰æ¶æ„**ï¼šä¸‰ä¸ªå­˜å‚¨å±‚æ¥å£å„å¼‚
```python
# æ¥å£ä¸ç»Ÿä¸€
faiss_store.add(embedding, doc_id)
falkor_store.create_node("Document", data)
metadata_store.insert(doc)
```

**æ ¸å¿ƒé—®é¢˜**ï¼š
- âŒ `HybridRepository` éœ€è¦äº†è§£æ¯ä¸ªå­˜å‚¨çš„å…·ä½“å®ç°
- âŒ éš¾ä»¥æ›¿æ¢å­˜å‚¨åç«¯ï¼ˆå¦‚ä» Faiss åˆ‡æ¢åˆ° Milvusï¼‰
- âŒ æµ‹è¯•æ—¶ Mock å¤æ‚åº¦é«˜

#### 2.3.2 ä¼˜åŒ–æ–¹æ¡ˆ

**ç›®æ ‡æ¶æ„**ï¼šå®šä¹‰ **StorageAdapter ç»Ÿä¸€æ¥å£**ï¼ˆé€‚é…å™¨æ¨¡å¼ï¼‰

```
storage/
â”œâ”€â”€ adapter.py              # ğŸ†• é€‚é…å™¨æŠ½è±¡æ¥å£
â”œâ”€â”€ adapters/               # ğŸ†• å…·ä½“é€‚é…å™¨
â”‚   â”œâ”€â”€ faiss_adapter.py
â”‚   â”œâ”€â”€ falkor_adapter.py
â”‚   â””â”€â”€ metadata_adapter.py
â”œâ”€â”€ faiss_store.py          # ä¿ç•™ï¼ˆåº•å±‚å®ç°ï¼‰
â”œâ”€â”€ falkor_store.py         # ä¿ç•™ï¼ˆåº•å±‚å®ç°ï¼‰
â””â”€â”€ metadata_store.py       # ä¿ç•™ï¼ˆåº•å±‚å®ç°ï¼‰
```

#### 2.3.3 æ ¸å¿ƒç±»è®¾è®¡

##### StorageAdapter æ¥å£

```python
# storage/adapter.py
class StorageAdapter(ABC):
    """å­˜å‚¨é€‚é…å™¨ç»Ÿä¸€æ¥å£
    
    è®¾è®¡ç›®æ ‡ï¼š
    1. ç»Ÿä¸€å­˜å‚¨æ“ä½œï¼ˆCRUDï¼‰
    2. è§£è€¦ Repository ä¸å…·ä½“å­˜å‚¨
    3. ç®€åŒ–æµ‹è¯•ï¼ˆMock å®¹æ˜“ï¼‰
    """
    
    @abstractmethod
    async def store(self, doc: Document) -> str:
        """å­˜å‚¨æ–‡æ¡£
        
        Args:
            doc: æ–‡æ¡£å¯¹è±¡
        
        Returns:
            doc_id: æ–‡æ¡£ ID
        """
        pass
    
    @abstractmethod
    async def search(
        self, 
        query: Any, 
        top_k: int = 10,
        filters: Optional[Dict] = None
    ) -> List[RetrievalResult]:
        """æœç´¢æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢ï¼ˆæ–‡æœ¬ã€å‘é‡ã€Cypher ç­‰ï¼‰
            top_k: è¿”å›æ•°é‡
            filters: è¿‡æ»¤æ¡ä»¶
        
        Returns:
            ç»“æœåˆ—è¡¨
        """
        pass
    
    @abstractmethod
    async def delete(self, doc_id: str) -> bool:
        """åˆ é™¤æ–‡æ¡£"""
        pass
    
    @abstractmethod
    async def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        pass
```

##### Faiss é€‚é…å™¨

```python
# storage/adapters/faiss_adapter.py
class FaissAdapter(StorageAdapter):
    """Faiss å­˜å‚¨é€‚é…å™¨"""
    
    def __init__(self, faiss_store: FaissStore, embedding_func):
        self.store = faiss_store
        self.embed = embedding_func
    
    async def store(self, doc: Document) -> str:
        """å­˜å‚¨æ–‡æ¡£ï¼ˆè‡ªåŠ¨å‘é‡åŒ–ï¼‰"""
        embedding = await self.embed(doc.content)
        await self.store.add(embedding, doc.id)
        return doc.id
    
    async def search(
        self, 
        query: str, 
        top_k: int = 10,
        filters: Optional[Dict] = None
    ) -> List[RetrievalResult]:
        """å‘é‡æ£€ç´¢"""
        query_embedding = await self.embed(query)
        faiss_results = await self.store.search(query_embedding, top_k)
        
        # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
        return [
            RetrievalResult(
                content="",  # éœ€è¦ä»å…ƒæ•°æ®åº“è·å–
                metadata={"doc_id": r["doc_id"]},
                score=r["score"],
                source="faiss"
            )
            for r in faiss_results
        ]
    
    async def delete(self, doc_id: str) -> bool:
        return await self.store.remove(doc_id)
    
    async def get_stats(self) -> Dict[str, Any]:
        return self.store.get_stats()
```

##### Falkor é€‚é…å™¨

```python
# storage/adapters/falkor_adapter.py
class FalkorAdapter(StorageAdapter):
    """Falkor å›¾è°±é€‚é…å™¨"""
    
    def __init__(self, falkor_store: FalkorStore):
        self.store = falkor_store
    
    async def store(self, doc: Document) -> str:
        """å­˜å‚¨æ–‡æ¡£ï¼ˆåˆ›å»ºèŠ‚ç‚¹ + å…³ç³»ï¼‰"""
        await self.store.create_node("Document", {
            "id": doc.id,
            "content": doc.content,
            "timestamp": doc.timestamp.isoformat()
        })
        
        # åˆ›å»ºå®ä½“å…³ç³»
        for entity in doc.entities:
            await self.store.create_relationship(
                doc.id, "MENTIONS", entity
            )
        
        return doc.id
    
    async def search(
        self, 
        query: str, 
        top_k: int = 10,
        filters: Optional[Dict] = None
    ) -> List[RetrievalResult]:
        """å›¾è°±æ£€ç´¢ï¼ˆCypher æŸ¥è¯¢ï¼‰"""
        # TODO: æå–å®ä½“ + Cypher æŸ¥è¯¢
        return []
    
    async def delete(self, doc_id: str) -> bool:
        await self.store.delete_node(doc_id)
        return True
    
    async def get_stats(self) -> Dict[str, Any]:
        return await self.store.get_stats()
```

#### 2.3.4 HybridRepository é‡æ„

```python
# repository/hybrid_repository.py
class HybridRepository:
    """æ··åˆä»“åº“ï¼ˆä½¿ç”¨ Adapter æ¨¡å¼ï¼‰"""
    
    def __init__(self, adapters: List[StorageAdapter]):
        """
        Args:
            adapters: å­˜å‚¨é€‚é…å™¨åˆ—è¡¨
                - FaissAdapterï¼ˆå‘é‡ï¼‰
                - FalkorAdapterï¼ˆå›¾è°±ï¼‰
                - MetadataAdapterï¼ˆå…ƒæ•°æ®ï¼‰
        """
        self.adapters = adapters
    
    async def store(self, doc: Document):
        """å¹¶è¡Œå­˜å‚¨åˆ°æ‰€æœ‰åç«¯"""
        tasks = [adapter.store(doc) for adapter in self.adapters]
        await asyncio.gather(*tasks)
    
    async def search(self, query: str, top_k: int = 10):
        """å¹¶è¡Œæœç´¢æ‰€æœ‰åç«¯"""
        tasks = [adapter.search(query, top_k) for adapter in self.adapters]
        results_list = await asyncio.gather(*tasks)
        
        # åˆå¹¶ç»“æœ
        all_results = []
        for results in results_list:
            all_results.extend(results)
        
        # å»é‡ + æ’åº
        return self._merge_results(all_results, top_k)
```

#### 2.3.5 æ”¶ç›Šåˆ†æ

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| **è€¦åˆåº¦** | é«˜ï¼ˆç›´æ¥ä¾èµ–ï¼‰ | ä½ï¼ˆæ¥å£ä¾èµ–ï¼‰ | -80% |
| **æµ‹è¯•æˆæœ¬** | Mock 3ä¸ªç±» | Mock 1ä¸ªæ¥å£ | -80% |
| **å¯æ›¿æ¢æ€§** | å›°éš¾ | ç®€å•ï¼ˆå®ç°æ¥å£ï¼‰ | é«˜ |
| **ä»£ç å¤ç”¨** | ä½ | é«˜ï¼ˆç»Ÿä¸€é€»è¾‘ï¼‰ | +50% |

---

### 2.4 æ•°æ®å¤„ç†ï¼šèŒè´£åˆ†ç¦»

#### 2.4.1 ç°çŠ¶é—®é¢˜

**å½“å‰æ¶æ„**ï¼š
```
data_processor/
â”œâ”€â”€ processor.py         # æ•°æ®å¤„ç†
â”œâ”€â”€ async_processor.py   # å¼‚æ­¥å¤„ç†ï¼ˆåŠŸèƒ½é‡å¤ï¼‰
â”œâ”€â”€ base.py
â””â”€â”€ analyzer.py          # æ•°æ®åˆ†æï¼ˆèŒè´£ä¸æ¸…ï¼‰
```

**æ ¸å¿ƒé—®é¢˜**ï¼š
- âŒ `processor` å’Œ `async_processor` åŠŸèƒ½é‡å¤
- âŒ `analyzer.py` æ··å…¥äº†åˆ†æé€»è¾‘ï¼Œåº”å±äºç‹¬ç«‹çš„ `analysis` æ¨¡å—
- âŒ ç¼ºå°‘æ¸…æ™°çš„ã€Œå¤„ç†ã€vsã€Œåˆ†æã€è¾¹ç•Œ

#### 2.4.2 ä¼˜åŒ–æ–¹æ¡ˆ

**ç›®æ ‡æ¶æ„**ï¼šæ‹†åˆ†ä¸ºä¸¤ä¸ªç‹¬ç«‹æ¨¡å—

```
data_processor/             # çº¯æ•°æ®å¤„ç†ï¼ˆETLï¼‰
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base.py
â”œâ”€â”€ text_processor.py       # æ–‡æœ¬æ¸…æ´—ã€åˆ†å—
â”œâ”€â”€ file_processor.py       # æ–‡ä»¶è§£æï¼ˆTXT/MD/PDF/DOCXï¼‰
â””â”€â”€ embedding_processor.py  # å‘é‡åŒ–

analysis/                   # æ•°æ®åˆ†æï¼ˆç‹¬ç«‹æ¨¡å—ï¼‰
â”œâ”€â”€ __init__.py
â”œâ”€â”€ pattern_analyzer.py     # è¡Œä¸ºæ¨¡å¼åˆ†æ
â”œâ”€â”€ trend_analyzer.py       # è¶‹åŠ¿åˆ†æ
â”œâ”€â”€ insight_generator.py    # æ´å¯Ÿç”Ÿæˆ
â””â”€â”€ emotion/                # æƒ…ç»ªåˆ†æ
    â””â”€â”€ emotion_engine.py
```

#### 2.4.3 èŒè´£åˆ’åˆ†

| æ¨¡å— | èŒè´£ | è¾“å…¥ | è¾“å‡º |
|------|------|------|------|
| **data_processor** | æ•°æ®æ¸…æ´—ã€æ ¼å¼è½¬æ¢ã€å‘é‡åŒ– | åŸå§‹æ–‡ä»¶/æ–‡æœ¬ | æ ‡å‡†åŒ–æ–‡æ¡£ |
| **analysis** | æ¨¡å¼æŒ–æ˜ã€è¶‹åŠ¿åˆ†æã€æ´å¯Ÿç”Ÿæˆ | æ ‡å‡†åŒ–æ–‡æ¡£ | åˆ†ææŠ¥å‘Š |

#### 2.4.4 æ ¸å¿ƒç±»è®¾è®¡

```python
# data_processor/text_processor.py
class TextProcessor:
    """æ–‡æœ¬å¤„ç†å™¨
    
    èŒè´£ï¼š
    - æ–‡æœ¬æ¸…æ´—
    - åˆ†å—ï¼ˆChunkingï¼‰
    - æ ¼å¼æ ‡å‡†åŒ–
    """
    
    async def clean(self, text: str) -> str:
        """æ–‡æœ¬æ¸…æ´—"""
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'[^\w\s\u4e00-\u9fff.,!?;:ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š""''ã€]', '', text)
        return text.strip()
    
    async def chunk(
        self, 
        text: str, 
        chunk_size: int = 500, 
        overlap: int = 50
    ) -> List[str]:
        """æ–‡æœ¬åˆ†å—ï¼ˆæ»‘åŠ¨çª—å£ï¼‰"""
        chunks = []
        start = 0
        while start < len(text):
            end = min(start + chunk_size, len(text))
            chunks.append(text[start:end])
            start += chunk_size - overlap
        return chunks

# analysis/pattern_analyzer.py
class PatternAnalyzer:
    """è¡Œä¸ºæ¨¡å¼åˆ†æå™¨
    
    èŒè´£ï¼š
    - è¯†åˆ«é«˜é¢‘ä¸»é¢˜
    - åˆ†ææ—¶é—´æ¨¡å¼
    - æŒ–æ˜å…³è”è§„åˆ™
    """
    
    async def analyze_topics(
        self, 
        documents: List[Document]
    ) -> List[Dict]:
        """é«˜é¢‘ä¸»é¢˜åˆ†æ"""
        entities = []
        for doc in documents:
            entities.extend(doc.entities)
        
        freq = Counter(entities)
        return [
            {"topic": e, "count": c}
            for e, c in freq.most_common(10)
        ]
```

---

## 3. ç®—æ³•ä¼˜åŒ–

### 3.1 è‡ªé€‚åº”æ··åˆæ£€ç´¢

#### 3.1.1 ä¼˜åŒ–ç›®æ ‡

**ç°çŠ¶é—®é¢˜**ï¼š
- å›ºå®šæƒé‡ï¼ˆå‘é‡ 0.6, å›¾è°± 0.4ï¼‰
- æ— æ³•æ ¹æ®æŸ¥è¯¢ç±»å‹è‡ªé€‚åº”

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼šæ ¹æ®æŸ¥è¯¢æ„å›¾åŠ¨æ€è°ƒæ•´æƒé‡

#### 3.1.2 ç®—æ³•è®¾è®¡

```python
# retrieval/stages/intent_adaptive_stage.pyï¼ˆå·²åœ¨ 2.1.3 ä¸­å®ç°ï¼‰

# å…³é”®ç®—æ³•
async def _classify_intent(self, query: str) -> str:
    """æ„å›¾åˆ†ç±»
    
    è§„åˆ™å¼•æ“ï¼š
    1. å…³é”®è¯åŒ¹é…ï¼ˆ"æ˜¯ä»€ä¹ˆ"â†’äº‹å®æ€§ï¼‰
    2. æ—¶é—´è¯æ£€æµ‹ï¼ˆ"æœ€è¿‘"â†’æ—¶åºæ€§ï¼‰
    3. å®ä½“å¯†åº¦ï¼ˆâ‰¥3ä¸ªâ†’å…³ç³»æ€§ï¼‰
    """
    if any(kw in query for kw in ["æ˜¯ä»€ä¹ˆ", "å®šä¹‰"]):
        return "factual"
    
    if any(kw in query for kw in ["ä»€ä¹ˆæ—¶å€™", "æœ€è¿‘"]):
        return "temporal"
    
    if any(kw in query for kw in ["å…³ç³»", "å½±å“"]):
        return "relational"
    
    # NER è¾…åŠ©åˆ¤æ–­
    entities = await self.ner.extract(query)
    if len(entities) >= 3:
        return "relational"
    
    return "factual"

# æƒé‡è°ƒæ•´ç­–ç•¥
adjustments = {
    "factual": {"vector": 1.2, "graph": 0.8},    # äº‹å®æ€§åå‘é‡
    "temporal": {"vector": 1.0, "graph": 1.0},   # æ—¶åºæ€§å‡è¡¡
    "relational": {"vector": 0.8, "graph": 1.2}  # å…³ç³»æ€§åå›¾è°±
}
```

#### 3.1.3 é¢„æœŸæ”¶ç›Š

- âœ… å‡†ç¡®ç‡æå‡ï¼š**+15-25%**
- âœ… æ— é¢å¤–æˆæœ¬ï¼ˆè§„åˆ™å¼•æ“ï¼‰
- âœ… é€Ÿåº¦å½±å“ï¼š<10ms

---

### 3.2 ä¸‰å±‚çº§ NER ç®—æ³•

#### 3.2.1 ä¼˜åŒ–ç›®æ ‡

**ç°çŠ¶é—®é¢˜**ï¼š
- å®Œå…¨ä¾èµ– LLM
- æˆæœ¬é«˜ï¼ˆ$0.002/æ¬¡ï¼‰
- é€Ÿåº¦æ…¢ï¼ˆ1-3sï¼‰

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼šä¸‰å±‚çº§çº§è”

#### 3.2.2 ç®—æ³•è®¾è®¡

| å±‚çº§ | æ–¹æ³• | å“åº”æ—¶é—´ | æˆæœ¬ | å‡†ç¡®ç‡ | ç½®ä¿¡åº¦é˜ˆå€¼ |
|------|------|----------|------|--------|-----------|
| Layer 1 | è§„åˆ™ï¼ˆAC è‡ªåŠ¨æœºï¼‰ | <10ms | $0 | 95%ï¼ˆè¯å…¸å†…ï¼‰ | 0.9 |
| Layer 2 | BERTï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰ | <100ms | $0 | 75% | 0.7 |
| Layer 3 | LLMï¼ˆå…œåº•ï¼‰ | 1-3s | $0.002 | 90% | 0.0 |

**æµç¨‹å›¾**ï¼š
```mermaid
graph TD
    A[è¾“å…¥æ–‡æœ¬] --> B[Layer 1: è§„åˆ™åŒ¹é…]
    B -->|ç½®ä¿¡åº¦ â‰¥ 0.9| C[è¿”å›ç»“æœ]
    B -->|ç½®ä¿¡åº¦ < 0.9| D[Layer 2: BERT]
    D -->|ç½®ä¿¡åº¦ â‰¥ 0.7| C
    D -->|ç½®ä¿¡åº¦ < 0.7| E[Layer 3: LLM]
    E --> C
```

#### 3.2.3 é¢„æœŸæ”¶ç›Š

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| **æˆæœ¬** | 100% LLM | 30% LLM | -70% |
| **å¹³å‡é€Ÿåº¦** | 2s | 500ms | +4å€ |
| **å‡†ç¡®ç‡** | 90% | 85-90% | åŸºæœ¬æŒå¹³ |

---

### 3.3 è¯­ä¹‰é‡æ’åºç®—æ³•

#### 3.3.1 ä¼˜åŒ–ç›®æ ‡

**ç°çŠ¶é—®é¢˜**ï¼š
- ç®€å•åŠ æƒèåˆ
- ç¼ºå°‘è¯­ä¹‰ç†è§£

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼šCross-Encoder + MMR

#### 3.3.2 ç®—æ³•è®¾è®¡

##### æ–¹æ¡ˆ Aï¼šåŸºäºè§„åˆ™çš„é‡æ’åºï¼ˆä½æˆæœ¬ï¼‰

```python
# å…³é”®è¯åŒ¹é… + è¯é‡å 
query_words = set(re.findall(r'\w+', query.lower()))
content_words = set(re.findall(r'\w+', result.content.lower()))
overlap = len(query_words & content_words)
boost = overlap / max(len(query_words), 1) * 0.1
result.score += boost
```

##### æ–¹æ¡ˆ Bï¼šLLM é‡æ’åºï¼ˆé«˜æˆæœ¬ã€é«˜å‡†ç¡®ç‡ï¼‰

```python
# LLM æ’åº
prompt = f"""æ ¹æ®æŸ¥è¯¢æ„å›¾ï¼Œå¯¹æ–‡æ¡£æŒ‰ç›¸å…³æ€§æ’åºã€‚

æŸ¥è¯¢ï¼š{query}

æ–‡æ¡£ï¼š
æ–‡æ¡£0: {doc0_content}
æ–‡æ¡£1: {doc1_content}
...

è¿”å›æ’åºåçš„ç¼–å·ï¼š0,2,1,3"""

response = await llm.generate(prompt)
indices = parse_indices(response)
```

#### 3.3.3 MMR å¤šæ ·æ€§æ§åˆ¶

```python
# MMR ç®—æ³•ï¼ˆå·²åœ¨ DiversityFilterStage ä¸­å®ç°ï¼‰
mmr_score = Î» * relevance - (1 - Î») * max_similarity

# Î» = 0.7: å¹³è¡¡ç›¸å…³æ€§å’Œå¤šæ ·æ€§
# Î» = 1.0: å®Œå…¨ç›¸å…³æ€§ä¼˜å…ˆ
# Î» = 0.0: å®Œå…¨å¤šæ ·æ€§ä¼˜å…ˆ
```

#### 3.3.4 é¢„æœŸæ”¶ç›Š

- âœ… å‡†ç¡®ç‡æå‡ï¼š**+10-20%**
- âœ… ç»“æœå¤šæ ·æ€§æå‡ï¼š**+30%**
- âœ… æˆæœ¬ï¼šå–å†³äºæ˜¯å¦å¯ç”¨ LLM

---

### 3.4 é£æ ¼æ¨¡ä»¿ç®—æ³•

#### 3.4.1 ä¼˜åŒ–ç›®æ ‡

**ç°çŠ¶é—®é¢˜**ï¼š
- Prompt å›ºå®š
- ç¼ºå°‘é£æ ¼ç‰¹å¾åº“

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼šç‰¹å¾æå– + åŠ¨æ€ Prompt

#### 3.4.2 ç®—æ³•è®¾è®¡

##### é£æ ¼ç‰¹å¾æå–

```python
class StyleExtractor:
    """é£æ ¼ç‰¹å¾æå–å™¨"""
    
    async def extract(self, documents: List[Document]) -> Dict:
        """æå–ç”¨æˆ·é£æ ¼ç‰¹å¾
        
        Returns:
            {
                "vocabulary": [...],        # é«˜é¢‘è¯æ±‡
                "sentence_patterns": [...], # å¥å¼ç‰¹ç‚¹
                "emotion_tendency": {...},  # æƒ…æ„Ÿå€¾å‘
                "topic_preference": [...]   # è¯é¢˜åå¥½
            }
        """
        # 1. è¯æ±‡åå¥½
        all_words = []
        for doc in documents:
            all_words.extend(jieba.cut(doc.content))
        vocab = Counter(all_words).most_common(100)
        
        # 2. å¥å¼ç‰¹ç‚¹
        sentences = [s for doc in documents for s in re.split(r'[ã€‚ï¼ï¼Ÿ]', doc.content)]
        avg_length = sum(len(s) for s in sentences) / max(len(sentences), 1)
        
        # 3. æƒ…æ„Ÿå€¾å‘
        emotions = [doc.metadata.get("emotion") for doc in documents]
        emotion_dist = Counter(emotions)
        
        return {
            "vocabulary": vocab,
            "avg_sentence_length": avg_length,
            "emotion_distribution": emotion_dist,
            "topic_preference": self._extract_topics(documents)
        }
```

##### åŠ¨æ€ Prompt æ„å»º

```python
async def build_mimic_prompt(
    self, 
    query: str, 
    style: Dict, 
    context: List[str]
) -> str:
    """æ„å»ºæ¨¡ä»¿ Prompt"""
    
    vocab_examples = ", ".join([w for w, _ in style["vocabulary"][:20]])
    
    prompt = f"""ä½ æ­£åœ¨æ¨¡ä»¿ç”¨æˆ·çš„è¯´è¯é£æ ¼ã€‚

ç”¨æˆ·é£æ ¼ç‰¹å¾ï¼š
- å¸¸ç”¨è¯æ±‡ï¼š{vocab_examples}
- å¹³å‡å¥é•¿ï¼š{style["avg_sentence_length"]:.0f}å­—
- æƒ…æ„Ÿå€¾å‘ï¼š{style["emotion_distribution"]}

å†å²å¯¹è¯ç¤ºä¾‹ï¼š
{chr(10).join(context[:3])}

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·ä»¥ç”¨æˆ·çš„é£æ ¼å›ç­”ï¼ˆæ³¨æ„ä½¿ç”¨å¸¸ç”¨è¯æ±‡å’Œå¥å¼ç‰¹ç‚¹ï¼‰ï¼š"""
    
    return prompt
```

#### 3.4.3 é¢„æœŸæ”¶ç›Š

- âœ… é£æ ¼ä¸€è‡´æ€§æå‡ï¼š**+30-40%**
- âœ… ä¸ªæ€§åŒ–ç¨‹åº¦æå‡ï¼š**æ˜¾è‘—**
- âœ… æˆæœ¬ï¼šåŸºæœ¬æŒå¹³ï¼ˆPrompt ç•¥é•¿ï¼‰

---

## 4. æ•°æ®æµè®¾è®¡

### 4.1 æ–‡æ¡£å­˜å‚¨æµç¨‹

```mermaid
graph TD
    A[åŸå§‹æ–‡æ¡£] --> B[TextProcessor æ¸…æ´—]
    B --> C[Chunking åˆ†å—]
    C --> D[NEREngine å®ä½“æå–]
    D --> E[EmotionEngine æƒ…ç»ªè¯†åˆ«]
    E --> F[EmbeddingProcessor å‘é‡åŒ–]
    F --> G{HybridRepository}
    G --> H[FaissAdapter]
    G --> I[FalkorAdapter]
    G --> J[MetadataAdapter]
```

### 4.2 æ£€ç´¢æµç¨‹

```mermaid
graph TD
    A[æŸ¥è¯¢æ–‡æœ¬] --> B[RetrievalPipeline]
    B --> C[VectorRetrievalStage]
    B --> D[GraphRetrievalStage]
    C --> E[FusionStage]
    D --> E
    E --> F[IntentAdaptiveStage]
    F --> G[SemanticRerankStage]
    G --> H[DiversityFilterStage]
    H --> I[è¿”å›ç»“æœ]
```

### 4.3 åˆ†ææµç¨‹

```mermaid
graph TD
    A[æ—¶é—´èŒƒå›´] --> B[AnalyzeEngine æ”¶é›†æ•°æ®]
    B --> C{åˆ†æç±»å‹}
    C -->|è¡Œä¸ºæ¨¡å¼| D[PatternAnalyzer]
    C -->|è¶‹åŠ¿åˆ†æ| E[TrendAnalyzer]
    C -->|æ´å¯Ÿç”Ÿæˆ| F[InsightGenerator]
    D --> G[ç”ŸæˆæŠ¥å‘Š]
    E --> G
    F --> G
```

---

## 5. æ¥å£è®¾è®¡

### 5.1 æ£€ç´¢æ¥å£

```python
# retrieval/factory.py
class RetrievalPipelineFactory:
    """Pipeline å·¥å‚ï¼ˆç®€åŒ–é…ç½®ï¼‰"""
    
    @staticmethod
    def create_basic(vector_retriever) -> RetrievalPipeline:
        """åŸºç¡€é…ç½®ï¼šå‘é‡æ£€ç´¢ + é‡æ’åº"""
        return RetrievalPipeline()\
            .add_stage(VectorRetrievalStage(vector_retriever))\
            .add_stage(SemanticRerankStage())
    
    @staticmethod
    def create_hybrid(
        vector_retriever, 
        graph_retriever, 
        ner_extractor,
        llm_caller
    ) -> RetrievalPipeline:
        """æ··åˆé…ç½®ï¼šå…¨åŠŸèƒ½æ£€ç´¢"""
        return RetrievalPipeline()\
            .add_stage(VectorRetrievalStage(vector_retriever, weight=0.6))\
            .add_stage(GraphRetrievalStage(graph_retriever, weight=0.4))\
            .add_stage(FusionStage())\
            .add_stage(IntentAdaptiveStage(ner_extractor))\
            .add_stage(SemanticRerankStage(llm_caller))\
            .add_stage(DiversityFilterStage(lambda_param=0.7))

# ä½¿ç”¨ç¤ºä¾‹
pipeline = RetrievalPipelineFactory.create_hybrid(
    vector_retriever,
    graph_retriever,
    ner_extractor,
    llm_caller
)

results = await pipeline.execute("æŸ¥è¯¢æ–‡æœ¬", top_k=10)
```

### 5.2 NER æ¥å£

```python
# ner/ner_engine.pyï¼ˆå·²åœ¨ 2.2.3 ä¸­å®šä¹‰ï¼‰

# ä½¿ç”¨ç¤ºä¾‹
ner_engine = NEREngine(
    dictionaries={
        "PERSON": ["å¼ ä¸‰", "æå››"],
        "LOCATION": ["åŒ—äº¬", "ä¸Šæµ·"]
    },
    llm_caller=llm_caller,
    use_bert=False  # å¯é€‰å¯ç”¨ BERT
)

entities = await ner_engine.extract("å¼ ä¸‰åœ¨åŒ—äº¬å·¥ä½œ")
# è¾“å‡ºï¼š[
#   Entity(text="å¼ ä¸‰", type="PERSON", score=0.95),
#   Entity(text="åŒ—äº¬", type="LOCATION", score=0.95)
# ]
```

### 5.3 å­˜å‚¨æ¥å£

```python
# repository/hybrid_repository.pyï¼ˆå·²åœ¨ 2.3.4 ä¸­å®šä¹‰ï¼‰

# ä½¿ç”¨ç¤ºä¾‹
repository = HybridRepository([
    FaissAdapter(faiss_store, embedding_func),
    FalkorAdapter(falkor_store),
    MetadataAdapter(metadata_store)
])

await repository.store(document)
results = await repository.search("æŸ¥è¯¢æ–‡æœ¬", top_k=10)
```

---

## 6. æµ‹è¯•ç­–ç•¥

### 6.1 å•å…ƒæµ‹è¯•

#### 6.1.1 Pipeline æµ‹è¯•

```python
# tests/unit/test_retrieval_pipeline.py
class TestRetrievalPipeline:
    """Pipeline å•å…ƒæµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_single_stage(self):
        """æµ‹è¯•å•é˜¶æ®µæ‰§è¡Œ"""
        mock_stage = Mock(StageBase)
        mock_stage.process.return_value = [
            RetrievalResult(content="test", score=0.9)
        ]
        
        pipeline = RetrievalPipeline().add_stage(mock_stage)
        results = await pipeline.execute("query", top_k=5)
        
        assert len(results) == 1
        assert results[0].score == 0.9
    
    @pytest.mark.asyncio
    async def test_multi_stage(self):
        """æµ‹è¯•å¤šé˜¶æ®µæ‰§è¡Œ"""
        stage1 = VectorRetrievalStage(mock_retriever)
        stage2 = SemanticRerankStage()
        
        pipeline = RetrievalPipeline()\
            .add_stage(stage1)\
            .add_stage(stage2)
        
        results = await pipeline.execute("query", top_k=10)
        assert len(results) <= 10
```

#### 6.1.2 Cascade Inference æµ‹è¯•

```python
# tests/unit/test_cascade_inference.py
class TestCascadeInference:
    """çº§è”æ¨ç†æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_early_return(self):
        """æµ‹è¯•æå‰è¿”å›ï¼ˆé«˜ç½®ä¿¡åº¦ï¼‰"""
        layer1 = Mock(InferenceLayer)
        layer1.infer.return_value = InferenceResult(
            confidence=0.95, data=["entity1"]
        )
        layer2 = Mock(InferenceLayer)  # ä¸åº”è¢«è°ƒç”¨
        
        cascade = CascadeInference()\
            .add_layer(layer1, confidence_threshold=0.9)\
            .add_layer(layer2, confidence_threshold=0.0)
        
        result = await cascade.infer("text")
        
        assert result.confidence == 0.95
        layer2.infer.assert_not_called()  # éªŒè¯æœªè°ƒç”¨
    
    @pytest.mark.asyncio
    async def test_fallback_to_last_layer(self):
        """æµ‹è¯•å…œåº•åˆ°æœ€åä¸€å±‚"""
        layer1 = Mock(InferenceLayer)
        layer1.infer.return_value = InferenceResult(confidence=0.5, data=[])
        layer2 = Mock(InferenceLayer)
        layer2.infer.return_value = InferenceResult(confidence=0.6, data=["entity"])
        
        cascade = CascadeInference()\
            .add_layer(layer1, confidence_threshold=0.9)\
            .add_layer(layer2, confidence_threshold=0.0)
        
        result = await cascade.infer("text")
        
        assert result.confidence == 0.6
        layer2.infer.assert_called_once()
```

### 6.2 é›†æˆæµ‹è¯•

```python
# tests/integration/test_rag_pipeline.py
class TestRAGPipeline:
    """RAG ç«¯åˆ°ç«¯æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_full_retrieval_flow(self):
        """æµ‹è¯•å®Œæ•´æ£€ç´¢æµç¨‹"""
        # 1. å­˜å‚¨æ–‡æ¡£
        doc = Document(
            id="doc1",
            content="æµ‹è¯•å†…å®¹",
            entities=["å®ä½“1"],
            doc_type=DocumentType.WORK_LOG
        )
        await repository.store(doc)
        
        # 2. æ£€ç´¢
        results = await pipeline.execute("æµ‹è¯•æŸ¥è¯¢", top_k=5)
        
        # 3. éªŒè¯
        assert len(results) > 0
        assert results[0].metadata["doc_id"] == "doc1"
```

### 6.3 æ€§èƒ½æµ‹è¯•

```python
# tests/performance/test_benchmark.py
class TestPerformance:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_ner_cost(self):
        """æµ‹è¯• NER æˆæœ¬ä¼˜åŒ–"""
        texts = ["çŸ­æ–‡æœ¬"] * 100 + ["é•¿æ–‡æœ¬" * 100] * 100
        
        start_time = time.time()
        llm_calls = 0
        
        for text in texts:
            result = await ner_engine.extract(text)
            if result.metadata["layer"] == "LLMNER":
                llm_calls += 1
        
        elapsed = time.time() - start_time
        
        # éªŒè¯ï¼šLLM è°ƒç”¨ < 30%
        assert llm_calls / len(texts) < 0.3
        
        # éªŒè¯ï¼šå¹³å‡é€Ÿåº¦ < 500ms
        assert elapsed / len(texts) < 0.5
```

---

## 7. è¿ç§»è®¡åˆ’

### 7.1 Phase 1ï¼šæ ¸å¿ƒæ¡†æ¶ï¼ˆ2å‘¨ï¼‰

| ä»»åŠ¡ | å·¥ä½œé‡ | ä¼˜å…ˆçº§ | è¾“å‡º |
|------|--------|--------|------|
| å®ç° `RetrievalPipeline` | 2äººå¤© | ğŸ”´ é«˜ | `retrieval/pipeline.py` |
| å®ç° `CascadeInference` | 2äººå¤© | ğŸ”´ é«˜ | `core/cascade_inference.py` |
| å®ç° `StorageAdapter` | 1äººå¤© | ğŸ”´ é«˜ | `storage/adapter.py` |
| å®ç° Pipeline Stages | 3äººå¤© | ğŸ”´ é«˜ | `retrieval/stages/` |
| ç¼–å†™å•å…ƒæµ‹è¯• | 2äººå¤© | ğŸ”´ é«˜ | `tests/unit/` |

### 7.2 Phase 2ï¼šç®—æ³•ä¼˜åŒ–ï¼ˆ2å‘¨ï¼‰

| ä»»åŠ¡ | å·¥ä½œé‡ | ä¼˜å…ˆçº§ | è¾“å‡º |
|------|--------|--------|------|
| å®ç°æ„å›¾è‡ªé€‚åº” | 2äººå¤© | ğŸ”´ é«˜ | `IntentAdaptiveStage` |
| å®ç°ä¸‰å±‚çº§ NER | 3äººå¤© | ğŸ”´ é«˜ | `NEREngine` + Layers |
| å®ç°è¯­ä¹‰é‡æ’åº | 2äººå¤© | ğŸŸ  ä¸­ | `SemanticRerankStage` |
| å®ç°é£æ ¼æå– | 2äººå¤© | ğŸŸ  ä¸­ | `StyleExtractor` |
| æ€§èƒ½åŸºå‡†æµ‹è¯• | 1äººå¤© | ğŸŸ  ä¸­ | `tests/performance/` |

### 7.3 Phase 3ï¼šæ¨¡å—é‡æ„ï¼ˆ1å‘¨ï¼‰

| ä»»åŠ¡ | å·¥ä½œé‡ | ä¼˜å…ˆçº§ | è¾“å‡º |
|------|--------|--------|------|
| æ‹†åˆ† `data_processor` | 1äººå¤© | ğŸŸ¡ ä½ | `data_processor/` + `analysis/` |
| åˆ é™¤ `async_processor.py` | 0.5äººå¤© | ğŸŸ¡ ä½ | - |
| åˆ é™¤ `hybrid_retriever.py` | 0.5äººå¤© | ğŸŸ¡ ä½ | - |
| åˆ é™¤ `reranker.py` | 0.5äººå¤© | ğŸŸ¡ ä½ | - |
| æ›´æ–°æ–‡æ¡£ | 1äººå¤© | ğŸŸ¡ ä½ | `README.md` |

### 7.4 è¿ç§»é£é™©

| é£é™© | å½±å“ | åº”å¯¹æªæ–½ |
|------|------|---------|
| Pipeline å¤æ‚åº¦é«˜ | ğŸ”´ é«˜ | æä¾›å·¥å‚æ–¹æ³•ç®€åŒ–é…ç½® |
| Cascade æ€§èƒ½é—®é¢˜ | ğŸŸ  ä¸­ | æ€§èƒ½æµ‹è¯•éªŒè¯ï¼Œä¼˜åŒ–ç½®ä¿¡åº¦é˜ˆå€¼ |
| å­˜å‚¨é€‚é…å™¨å…¼å®¹æ€§ | ğŸŸ  ä¸­ | å……åˆ†çš„é›†æˆæµ‹è¯• |
| å­¦ä¹ æ›²çº¿é™¡å³­ | ğŸŸ¡ ä½ | ç¼–å†™è¯¦ç»†æ–‡æ¡£å’Œç¤ºä¾‹ |

---

## 8. æ–‡ä»¶ç»“æ„å¯¹æ¯”

### 8.1 ä¼˜åŒ–å‰

```
ame/
â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ vector_retriever.py
â”‚   â”œâ”€â”€ graph_retriever.py
â”‚   â”œâ”€â”€ hybrid_retriever.py    # âŒ åˆ é™¤
â”‚   â”œâ”€â”€ reranker.py             # âŒ åˆ é™¤
â”‚   â””â”€â”€ base.py
â”œâ”€â”€ ner/
â”‚   â”œâ”€â”€ simple_ner.py
â”‚   â”œâ”€â”€ llm_ner.py
â”‚   â”œâ”€â”€ hybrid_ner.py           # âŒ é‡æ„
â”‚   â””â”€â”€ base.py
â”œâ”€â”€ data_processor/
â”‚   â”œâ”€â”€ processor.py
â”‚   â”œâ”€â”€ async_processor.py      # âŒ åˆ é™¤
â”‚   â””â”€â”€ analyzer.py             # âŒ ç§»åŠ¨
â””â”€â”€ storage/
    â”œâ”€â”€ faiss_store.py
    â”œâ”€â”€ falkor_store.py
    â””â”€â”€ metadata_store.py
```

### 8.2 ä¼˜åŒ–å

```
ame/
â”œâ”€â”€ core/                       # ğŸ†• æ ¸å¿ƒæ¡†æ¶
â”‚   â”œâ”€â”€ cascade_inference.py
â”‚   â””â”€â”€ inference_layer.py
â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ pipeline.py             # ğŸ†• Pipeline å¼•æ“
â”‚   â”œâ”€â”€ stages/                 # ğŸ†• æ£€ç´¢é˜¶æ®µ
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ vector_stage.py
â”‚   â”‚   â”œâ”€â”€ graph_stage.py
â”‚   â”‚   â”œâ”€â”€ fusion_stage.py
â”‚   â”‚   â”œâ”€â”€ rerank_stage.py
â”‚   â”‚   â”œâ”€â”€ diversity_stage.py
â”‚   â”‚   â””â”€â”€ intent_adaptive_stage.py
â”‚   â”œâ”€â”€ factory.py              # ğŸ†• å·¥å‚æ–¹æ³•
â”‚   â”œâ”€â”€ vector_retriever.py     # ä¿ç•™
â”‚   â”œâ”€â”€ graph_retriever.py      # ä¿ç•™
â”‚   â””â”€â”€ base.py
â”œâ”€â”€ ner/
â”‚   â”œâ”€â”€ ner_engine.py           # ğŸ†• NER å¼•æ“
â”‚   â”œâ”€â”€ layers/                 # ğŸ†• NER å±‚
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ rule_layer.py
â”‚   â”‚   â”œâ”€â”€ bert_layer.py
â”‚   â”‚   â””â”€â”€ llm_layer.py
â”‚   â””â”€â”€ base.py
â”œâ”€â”€ data_processor/             # çº¯æ•°æ®å¤„ç†
â”‚   â”œâ”€â”€ text_processor.py       # ğŸ†•
â”‚   â”œâ”€â”€ file_processor.py       # ğŸ†•
â”‚   â””â”€â”€ embedding_processor.py  # ğŸ†•
â”œâ”€â”€ analysis/                   # ğŸ†• ç‹¬ç«‹åˆ†ææ¨¡å—
â”‚   â”œâ”€â”€ pattern_analyzer.py
â”‚   â”œâ”€â”€ trend_analyzer.py
â”‚   â”œâ”€â”€ insight_generator.py
â”‚   â””â”€â”€ emotion/
â”‚       â”œâ”€â”€ emotion_engine.py   # ğŸ†•
â”‚       â””â”€â”€ layers/
â”‚           â”œâ”€â”€ lexicon_layer.py
â”‚           â”œâ”€â”€ bert_layer.py
â”‚           â””â”€â”€ llm_layer.py
â””â”€â”€ storage/
    â”œâ”€â”€ adapter.py              # ğŸ†• é€‚é…å™¨æ¥å£
    â”œâ”€â”€ adapters/               # ğŸ†• å…·ä½“é€‚é…å™¨
    â”‚   â”œâ”€â”€ faiss_adapter.py
    â”‚   â”œâ”€â”€ falkor_adapter.py
    â”‚   â””â”€â”€ metadata_adapter.py
    â”œâ”€â”€ faiss_store.py          # ä¿ç•™
    â”œâ”€â”€ falkor_store.py         # ä¿ç•™
    â””â”€â”€ metadata_store.py       # ä¿ç•™
```

---

## 9. æ€§èƒ½æŒ‡æ ‡

### 9.1 ä¼˜åŒ–ç›®æ ‡

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| **æ£€ç´¢å‡†ç¡®ç‡** | 70% | 85-95% | +15-25% |
| **API æˆæœ¬** | $1.00/100æ¬¡ | $0.30/100æ¬¡ | -70% |
| **å¹³å‡å“åº”é€Ÿåº¦** | 2-3s | 500ms-1s | +3-5å€ |
| **ä»£ç å¤ç”¨ç‡** | 30% | 100% | +70% |
| **æµ‹è¯•è¦†ç›–ç‡** | 60% | 90% | +30% |

### 9.2 æˆæœ¬åˆ†æ

#### ä¼˜åŒ–å‰ï¼ˆ100 æ¬¡æŸ¥è¯¢ï¼‰

| æ“ä½œ | è°ƒç”¨æ¬¡æ•° | å•ä»· | æ€»æˆæœ¬ |
|------|---------|------|--------|
| NER (LLM) | 100 | $0.002 | $0.20 |
| æ£€ç´¢ (Embedding) | 100 | $0.0001 | $0.01 |
| é‡æ’åº (LLM) | 50 | $0.005 | $0.25 |
| **æ€»è®¡** | - | - | **$0.46** |

#### ä¼˜åŒ–åï¼ˆ100 æ¬¡æŸ¥è¯¢ï¼‰

| æ“ä½œ | è°ƒç”¨æ¬¡æ•° | å•ä»· | æ€»æˆæœ¬ |
|------|---------|------|--------|
| NER (è§„åˆ™/BERT) | 70 | $0 | $0 |
| NER (LLM å…œåº•) | 30 | $0.002 | $0.06 |
| æ£€ç´¢ (Embedding) | 100 | $0.0001 | $0.01 |
| é‡æ’åº (è§„åˆ™) | 80 | $0 | $0 |
| é‡æ’åº (LLM) | 20 | $0.005 | $0.10 |
| **æ€»è®¡** | - | - | **$0.17** |

**æˆæœ¬é™ä½ï¼š63%**

---

## 10. å…³é”®ç±»å›¾

### 10.1 Pipeline æ¶æ„

```mermaid
classDiagram
    class RetrievalPipeline {
        -List~StageBase~ stages
        +add_stage(stage) RetrievalPipeline
        +execute(query, top_k) List~RetrievalResult~
    }
    
    class StageBase {
        <<abstract>>
        +process(query, results, context)* List~RetrievalResult~
        +get_name()* str
    }
    
    class VectorRetrievalStage {
        -VectorRetriever retriever
        -float weight
        +process() List~RetrievalResult~
        +get_name() str
    }
    
    class FusionStage {
        -str fusion_method
        +process() List~RetrievalResult~
        +get_name() str
    }
    
    class IntentAdaptiveStage {
        -NEREngine ner
        +process() List~RetrievalResult~
        -_classify_intent() str
        +get_name() str
    }
    
    RetrievalPipeline o-- StageBase
    StageBase <|-- VectorRetrievalStage
    StageBase <|-- FusionStage
    StageBase <|-- IntentAdaptiveStage
```

### 10.2 Cascade Inference

```mermaid
classDiagram
    class CascadeInference {
        -List~Dict~ layers
        +add_layer(layer, threshold) CascadeInference
        +infer(input_data) InferenceResult
    }
    
    class InferenceLayer {
        <<abstract>>
        +infer(input_data)* InferenceResult
        +get_name()* str
    }
    
    class RuleNERLayer {
        -Dict dictionaries
        +infer(text) InferenceResult
        +get_name() str
    }
    
    class BertNERLayer {
        -Model model
        +infer(text) InferenceResult
        +get_name() str
    }
    
    class LLMNERLayer {
        -LLMCaller llm
        +infer(text) InferenceResult
        -_parse_entities() List~Entity~
        +get_name() str
    }
    
    CascadeInference o-- InferenceLayer
    InferenceLayer <|-- RuleNERLayer
    InferenceLayer <|-- BertNERLayer
    InferenceLayer <|-- LLMNERLayer
```

### 10.3 Storage Adapter

```mermaid
classDiagram
    class StorageAdapter {
        <<abstract>>
        +store(doc)* str
        +search(query, top_k)* List~RetrievalResult~
        +delete(doc_id)* bool
        +get_stats()* Dict
    }
    
    class FaissAdapter {
        -FaissStore store
        -EmbeddingFunc embed
        +store(doc) str
        +search(query, top_k) List~RetrievalResult~
        +delete(doc_id) bool
        +get_stats() Dict
    }
    
    class FalkorAdapter {
        -FalkorStore store
        +store(doc) str
        +search(query, top_k) List~RetrievalResult~
        +delete(doc_id) bool
        +get_stats() Dict
    }
    
    class HybridRepository {
        -List~StorageAdapter~ adapters
        +store(doc) void
        +search(query, top_k) List~RetrievalResult~
        -_merge_results() List~RetrievalResult~
    }
    
    StorageAdapter <|-- FaissAdapter
    StorageAdapter <|-- FalkorAdapter
    HybridRepository o-- StorageAdapter
```
    def get_name(self) -> str:
        return "RuleNER"

# ner/layers/bert_layer.py
class BertNERLayer(InferenceLayer):
    """BERT NER å±‚
    
    ç‰¹æ€§ï¼š
    - ä½æˆæœ¬ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰
    - 100ms å†…å“åº”
    - ä¸­ç­‰å‡†ç¡®ç‡
    """
    
    def __init__(self, model_path: Optional[str] = None):
        # TODO: åŠ è½½ BERT æ¨¡å‹
        self.model = None
    
    async def infer(self, text: str) -> InferenceResult:
        if not self.model:
            return InferenceResult(confidence=0.0, data=[])
        
        # TODO: BERT æ¨ç†
        entities = []  # æ¨¡å‹è¾“å‡º
        
        # ç½®ä¿¡åº¦ï¼šæ¨¡å‹è¾“å‡ºçš„å¹³å‡åˆ†æ•°
        confidence = 0.75 if entities else 0.5
        
        return InferenceResult(
            confidence=confidence,
            data=entities,
            metadata={"method": "bert"}
        )
    
    def get_name(self) -> str:
        return "BertNER"

# ner/layers/llm_layer.py
class LLMNERLayer(InferenceLayer):
    """LLM NER å±‚
    
    ç‰¹æ€§ï¼š
    - é«˜æˆæœ¬ï¼ˆ$0.002/æ¬¡ï¼‰
    - 1-3s å“åº”
    - é«˜å‡†ç¡®ç‡
    """
    
    def __init__(self, llm_caller):
        self.llm = llm_caller
    
    async def infer(self, text: str) -> InferenceResult:
        prompt = f"""æå–æ–‡æœ¬ä¸­çš„å®ä½“ï¼š

æ–‡æœ¬ï¼š{text}

è¿”å›JSONæ ¼å¼ï¼š
[
  {{"text": "å®ä½“å", "type": "PERSON|LOCATION|ORGANIZATION|TOPIC", "score": 0.0-1.0}},
  ...
]"""
        
        response = await self.llm.generate(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        
        # è§£æ JSON
        entities = self._parse_entities(response.content)
        
        # LLM é»˜è®¤é«˜ç½®ä¿¡åº¦
        confidence = 0.95 if entities else 0.7
        
        return InferenceResult(
            confidence=confidence,
            data=entities,
            metadata={"method": "llm", "cost": 0.002}
        )
    
    def _parse_entities(self, text: str) -> List[Entity]:
        import json, re
        try:
            json_match = re.search(r'\[.*\]', text, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
                return [Entity(**item) for item in data]
        except:
            pass
        return []
    
    def get_name(self) -> str:
        return "LLMNER"
```

##### NER å¼•æ“

```python
# ner/ner_engine.py
class NEREngine:
    """NER å¼•æ“ï¼ˆä½¿ç”¨ Cascade Inferenceï¼‰"""
    
    def __init__(
        self,
        dictionaries: Dict[str, List[str]],
        llm_caller,
        use_bert: bool = False
    ):
        # æ„å»ºçº§è”æ¨ç†
        self.cascade = CascadeInference()
        
        # Layer 1: è§„åˆ™å±‚ï¼ˆå¿«é€Ÿã€é›¶æˆæœ¬ï¼‰
        self.cascade.add_layer(
            RuleNERLayer(dictionaries),
            confidence_threshold=0.9
        )
        
        # Layer 2: BERT å±‚ï¼ˆå¯é€‰ï¼Œä¸­é€Ÿã€ä½æˆæœ¬ï¼‰
        if use_bert:
            self.cascade.add_layer(
                BertNERLayer(),
                confidence_threshold=0.7
            )
        
        # Layer 3: LLM å±‚ï¼ˆå…œåº•ï¼Œæ…¢é€Ÿã€é«˜æˆæœ¬ï¼‰
        self.cascade.add_layer(
            LLMNERLayer(llm_caller),
            confidence_threshold=0.0  # å…œåº•å±‚æ— é˜ˆå€¼
        )
    
    async def extract(self, text: str) -> List[Entity]:
        """æå–å®ä½“"""
        result = await self.cascade.infer(text)
        return result.data
```

##### æƒ…ç»ªè¯†åˆ«å¼•æ“

```python
# analysis/emotion/emotion_engine.py
class EmotionEngine:
    """æƒ…ç»ªè¯†åˆ«å¼•æ“ï¼ˆä½¿ç”¨ Cascade Inferenceï¼‰"""
    
    def __init__(self, llm_caller, use_bert: bool = False):
        self.cascade = CascadeInference()
        
        # Layer 1: è¯å…¸å±‚ï¼ˆæƒ…æ„Ÿè¯å…¸ï¼‰
        self.cascade.add_layer(
            LexiconEmotionLayer(),
            confidence_threshold=0.8
        )
        
        # Layer 2: BERT å±‚ï¼ˆå¯é€‰ï¼‰
        if use_bert:
            self.cascade.add_layer(
                BertEmotionLayer(),
                confidence_threshold=0.7
            )
        
        # Layer 3: LLM å±‚ï¼ˆå…œåº•ï¼‰
        self.cascade.add_layer(
            LLMEmotionLayer(llm_caller),
            confidence_threshold=0.0
        )
    
    async def detect(self, text: str) -> Dict[str, Any]:
        """æ£€æµ‹æƒ…ç»ª"""
        result = await self.cascade.infer(text)
        return result.data
```

#### 2.2.4 æ”¶ç›Šåˆ†æ

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| **ä»£ç å¤ç”¨** | é‡å¤é€»è¾‘ | ç»Ÿä¸€æ¡†æ¶ | +70% |
| **æˆæœ¬** | 100% LLM | 30% LLMï¼ˆ70%è§„åˆ™/BERTï¼‰ | -70% |
| **é€Ÿåº¦** | 1-3s | 10ms-100msï¼ˆè§„åˆ™/BERTï¼‰ | +10-30å€ |
| **å¯æ‰©å±•æ€§** | å›°éš¾ | æ–°å¢å±‚çº§å³å¯ | é«˜ |

---

### 2.3 å­˜å‚¨å±‚ï¼šStorageAdapter ç»Ÿä¸€æ¥å£

#### 2.3.1 ç°çŠ¶é—®é¢˜

**å½“å‰æ¶æ„**ï¼šä¸‰ä¸ªå­˜å‚¨å±‚æ¥å£å„å¼‚
```python
# æ¥å£ä¸ç»Ÿä¸€
faiss_store.add(embedding, doc_id)
falkor_store.create_node("Document", data)
metadata_store.insert(doc)
```

**æ ¸å¿ƒé—®é¢˜**ï¼š
- âŒ `HybridRepository` éœ€è¦äº†è§£æ¯ä¸ªå­˜å‚¨çš„å…·ä½“å®ç°
- âŒ éš¾ä»¥æ›¿æ¢å­˜å‚¨åç«¯ï¼ˆå¦‚ä» Faiss åˆ‡æ¢åˆ° Milvusï¼‰
- âŒ æµ‹è¯•æ—¶ Mock å¤æ‚åº¦é«˜

#### 2.3.2 ä¼˜åŒ–æ–¹æ¡ˆ

**ç›®æ ‡æ¶æ„**ï¼šå®šä¹‰ **StorageAdapter ç»Ÿä¸€æ¥å£**ï¼ˆé€‚é…å™¨æ¨¡å¼ï¼‰

```
storage/
â”œâ”€â”€ adapter.py              # ğŸ†• é€‚é…å™¨æŠ½è±¡æ¥å£
â”œâ”€â”€ adapters/               # ğŸ†• å…·ä½“é€‚é…å™¨
â”‚   â”œâ”€â”€ faiss_adapter.py
â”‚   â”œâ”€â”€ falkor_adapter.py
â”‚   â””â”€â”€ metadata_adapter.py
â”œâ”€â”€ faiss_store.py          # ä¿ç•™ï¼ˆåº•å±‚å®ç°ï¼‰
â”œâ”€â”€ falkor_store.py         # ä¿ç•™ï¼ˆåº•å±‚å®ç°ï¼‰
â””â”€â”€ metadata_store.py       # ä¿ç•™ï¼ˆåº•å±‚å®ç°ï¼‰
```

#### 2.3.3 æ ¸å¿ƒç±»è®¾è®¡

##### StorageAdapter æ¥å£

```python
# storage/adapter.py
class StorageAdapter(ABC):
    """å­˜å‚¨é€‚é…å™¨ç»Ÿä¸€æ¥å£
    
    è®¾è®¡ç›®æ ‡ï¼š
    1. ç»Ÿä¸€å­˜å‚¨æ“ä½œï¼ˆCRUDï¼‰
    2. è§£è€¦ Repository ä¸å…·ä½“å­˜å‚¨
    3. ç®€åŒ–æµ‹è¯•ï¼ˆMock å®¹æ˜“ï¼‰
    """
    
    @abstractmethod
    async def store(self, doc: Document) -> str:
        """å­˜å‚¨æ–‡æ¡£
        
        Args:
            doc: æ–‡æ¡£å¯¹è±¡
        
        Returns:
            doc_id: æ–‡æ¡£ ID
        """
        pass
    
    @abstractmethod
    async def search(
        self, 
        query: Any, 
        top_k: int = 10,
        filters: Optional[Dict] = None
    ) -> List[RetrievalResult]:
        """æœç´¢æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢ï¼ˆæ–‡æœ¬ã€å‘é‡ã€Cypher ç­‰ï¼‰
            top_k: è¿”å›æ•°é‡
            filters: è¿‡æ»¤æ¡ä»¶
        
        Returns:
            ç»“æœåˆ—è¡¨
        """
        pass
    
    @abstractmethod
    async def delete(self, doc_id: str) -> bool:
        """åˆ é™¤æ–‡æ¡£"""
        pass
    
    @abstractmethod
    async def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        pass
```

##### Faiss é€‚é…å™¨

```python
# storage/adapters/faiss_adapter.py
class FaissAdapter(StorageAdapter):
    """Faiss å­˜å‚¨é€‚é…å™¨"""
    
    def __init__(self, faiss_store: FaissStore, embedding_func):
        self.store = faiss_store
        self.embed = embedding_func
    
    async def store(self, doc: Document) -> str:
        """å­˜å‚¨æ–‡æ¡£ï¼ˆè‡ªåŠ¨å‘é‡åŒ–ï¼‰"""
        embedding = await self.embed(doc.content)
        await self.store.add(embedding, doc.id)
        return doc.id
    
    async def search(
        self, 
        query: str, 
        top_k: int = 10,
        filters: Optional[Dict] = None
    ) -> List[RetrievalResult]:
        """å‘é‡æ£€ç´¢"""
        query_embedding = await self.embed(query)
        faiss_results = await self.store.search(query_embedding, top_k)
        
        # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
        return [
            RetrievalResult(
                content="",  # éœ€è¦ä»å…ƒæ•°æ®åº“è·å–
                metadata={"doc_id": r["doc_id"]},
                score=r["score"],
                source="faiss"
            )
            for r in faiss_results
        ]
    
    async def delete(self, doc_id: str) -> bool:
        return await self.store.remove(doc_id)
    
    async def get_stats(self) -> Dict[str, Any]:
        return self.store.get_stats()
```

##### Falkor é€‚é…å™¨

```python
# storage/adapters/falkor_adapter.py
class FalkorAdapter(StorageAdapter):
    """Falkor å›¾è°±é€‚é…å™¨"""
    
    def __init__(self, falkor_store: FalkorStore):
        self.store = falkor_store
    
    async def store(self, doc: Document) -> str:
        """å­˜å‚¨æ–‡æ¡£ï¼ˆåˆ›å»ºèŠ‚ç‚¹ + å…³ç³»ï¼‰"""
        await self.store.create_node("Document", {
            "id": doc.id,
            "content": doc.content,
            "timestamp": doc.timestamp.isoformat()
        })
        
        # åˆ›å»ºå®ä½“å…³ç³»
        for entity in doc.entities:
            await self.store.create_relationship(
                doc.id, "MENTIONS", entity
            )
        
        return doc.id
    
    async def search(
        self, 
        query: str, 
        top_k: int = 10,
        filters: Optional[Dict] = None
    ) -> List[RetrievalResult]:
        """å›¾è°±æ£€ç´¢ï¼ˆCypher æŸ¥è¯¢ï¼‰"""
        # TODO: æå–å®ä½“ + Cypher æŸ¥è¯¢
        return []
    
    async def delete(self, doc_id: str) -> bool:
        await self.store.delete_node(doc_id)
        return True
    
    async def get_stats(self) -> Dict[str, Any]:
        return await self.store.get_stats()
```

#### 2.3.4 HybridRepository é‡æ„

```python
# repository/hybrid_repository.py
class HybridRepository:
    """æ··åˆä»“åº“ï¼ˆä½¿ç”¨ Adapter æ¨¡å¼ï¼‰"""
    
    def __init__(self, adapters: List[StorageAdapter]):
        """
        Args:
            adapters: å­˜å‚¨é€‚é…å™¨åˆ—è¡¨
                - FaissAdapterï¼ˆå‘é‡ï¼‰
                - FalkorAdapterï¼ˆå›¾è°±ï¼‰
                - MetadataAdapterï¼ˆå…ƒæ•°æ®ï¼‰
        """
        self.adapters = adapters
    
    async def store(self, doc: Document):
        """å¹¶è¡Œå­˜å‚¨åˆ°æ‰€æœ‰åç«¯"""
        tasks = [adapter.store(doc) for adapter in self.adapters]
        await asyncio.gather(*tasks)
    
    async def search(self, query: str, top_k: int = 10):
        """å¹¶è¡Œæœç´¢æ‰€æœ‰åç«¯"""
        tasks = [adapter.search(query, top_k) for adapter in self.adapters]
        results_list = await asyncio.gather(*tasks)
        
        # åˆå¹¶ç»“æœ
        all_results = []
        for results in results_list:
            all_results.extend(results)
        
        # å»é‡ + æ’åº
        return self._merge_results(all_results, top_k)
```

#### 2.3.5 æ”¶ç›Šåˆ†æ

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| **è€¦åˆåº¦** | é«˜ï¼ˆç›´æ¥ä¾èµ–ï¼‰ | ä½ï¼ˆæ¥å£ä¾èµ–ï¼‰ | -80% |
| **æµ‹è¯•æˆæœ¬** | Mock 3ä¸ªç±» | Mock 1ä¸ªæ¥å£ | -80% |
| **å¯æ›¿æ¢æ€§** | å›°éš¾ | ç®€å•ï¼ˆå®ç°æ¥å£ï¼‰ | é«˜ |
| **ä»£ç å¤ç”¨** | ä½ | é«˜ï¼ˆç»Ÿä¸€é€»è¾‘ï¼‰ | +50% |

---

### 2.4 æ•°æ®å¤„ç†ï¼šèŒè´£åˆ†ç¦»

#### 2.4.1 ç°çŠ¶é—®é¢˜

**å½“å‰æ¶æ„**ï¼š
```
data_processor/
â”œâ”€â”€ processor.py         # æ•°æ®å¤„ç†
â”œâ”€â”€ async_processor.py   # å¼‚æ­¥å¤„ç†ï¼ˆåŠŸèƒ½é‡å¤ï¼‰
â”œâ”€â”€ base.py
â””â”€â”€ analyzer.py          # æ•°æ®åˆ†æï¼ˆèŒè´£ä¸æ¸…ï¼‰
```

**æ ¸å¿ƒé—®é¢˜**ï¼š
- âŒ `processor` å’Œ `async_processor` åŠŸèƒ½é‡å¤
- âŒ `analyzer.py` æ··å…¥äº†åˆ†æé€»è¾‘ï¼Œåº”å±äºç‹¬ç«‹çš„ `analysis` æ¨¡å—
- âŒ ç¼ºå°‘æ¸…æ™°çš„ã€Œå¤„ç†ã€vsã€Œåˆ†æã€è¾¹ç•Œ

#### 2.4.2 ä¼˜åŒ–æ–¹æ¡ˆ

**ç›®æ ‡æ¶æ„**ï¼šæ‹†åˆ†ä¸ºä¸¤ä¸ªç‹¬ç«‹æ¨¡å—

```
data_processor/             # çº¯æ•°æ®å¤„ç†ï¼ˆETLï¼‰
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base.py
â”œâ”€â”€ text_processor.py       # æ–‡æœ¬æ¸…æ´—ã€åˆ†å—
â”œâ”€â”€ file_processor.py       # æ–‡ä»¶è§£æï¼ˆTXT/MD/PDF/DOCXï¼‰
â””â”€â”€ embedding_processor.py  # å‘é‡åŒ–

analysis/                   # æ•°æ®åˆ†æï¼ˆç‹¬ç«‹æ¨¡å—ï¼‰
â”œâ”€â”€ __init__.py
â”œâ”€â”€ pattern_analyzer.py     # è¡Œä¸ºæ¨¡å¼åˆ†æ
â”œâ”€â”€ trend_analyzer.py       # è¶‹åŠ¿åˆ†æ
â”œâ”€â”€ insight_generator.py    # æ´å¯Ÿç”Ÿæˆ
â””â”€â”€ emotion/                # æƒ…ç»ªåˆ†æ
    â””â”€â”€ emotion_engine.py
```

#### 2.4.3 èŒè´£åˆ’åˆ†

| æ¨¡å— | èŒè´£ | è¾“å…¥ | è¾“å‡º |
|------|------|------|------|
| **data_processor** | æ•°æ®æ¸…æ´—ã€æ ¼å¼è½¬æ¢ã€å‘é‡åŒ– | åŸå§‹æ–‡ä»¶/æ–‡æœ¬ | æ ‡å‡†åŒ–æ–‡æ¡£ |
| **analysis** | æ¨¡å¼æŒ–æ˜ã€è¶‹åŠ¿åˆ†æã€æ´å¯Ÿç”Ÿæˆ | æ ‡å‡†åŒ–æ–‡æ¡£ | åˆ†ææŠ¥å‘Š |

#### 2.4.4 æ ¸å¿ƒç±»è®¾è®¡

```python
# data_processor/text_processor.py
class TextProcessor:
    """æ–‡æœ¬å¤„ç†å™¨
    
    èŒè´£ï¼š
    - æ–‡æœ¬æ¸…æ´—
    - åˆ†å—ï¼ˆChunkingï¼‰
    - æ ¼å¼æ ‡å‡†åŒ–
    """
    
    async def clean(self, text: str) -> str:
        """æ–‡æœ¬æ¸…æ´—"""
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'[^\w\s\u4e00-\u9fff.,!?;:ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š""''ã€]', '', text)
        return text.strip()
    
    async def chunk(
        self, 
        text: str, 
        chunk_size: int = 500, 
        overlap: int = 50
    ) -> List[str]:
        """æ–‡æœ¬åˆ†å—ï¼ˆæ»‘åŠ¨çª—å£ï¼‰"""
        chunks = []
        start = 0
        while start < len(text):
            end = min(start + chunk_size, len(text))
            chunks.append(text[start:end])
            start += chunk_size - overlap
        return chunks

# analysis/pattern_analyzer.py
class PatternAnalyzer:
    """è¡Œä¸ºæ¨¡å¼åˆ†æå™¨
    
    èŒè´£ï¼š
    - è¯†åˆ«é«˜é¢‘ä¸»é¢˜
    - åˆ†ææ—¶é—´æ¨¡å¼
    - æŒ–æ˜å…³è”è§„åˆ™
    """
    
    async def analyze_topics(
        self, 
        documents: List[Document]
    ) -> List[Dict]:
        """é«˜é¢‘ä¸»é¢˜åˆ†æ"""
        entities = []
        for doc in documents:
            entities.extend(doc.entities)
        
        freq = Counter(entities)
        return [
            {"topic": e, "count": c}
            for e, c in freq.most_common(10)
        ]
```

---

## 3. ç®—æ³•ä¼˜åŒ–

### 3.1 è‡ªé€‚åº”æ··åˆæ£€ç´¢

#### 3.1.1 ä¼˜åŒ–ç›®æ ‡

**ç°çŠ¶é—®é¢˜**ï¼š
- å›ºå®šæƒé‡ï¼ˆå‘é‡ 0.6, å›¾è°± 0.4ï¼‰
- æ— æ³•æ ¹æ®æŸ¥è¯¢ç±»å‹è‡ªé€‚åº”

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼šæ ¹æ®æŸ¥è¯¢æ„å›¾åŠ¨æ€è°ƒæ•´æƒé‡

#### 3.1.2 ç®—æ³•è®¾è®¡

```python
# retrieval/stages/intent_adaptive_stage.pyï¼ˆå·²åœ¨ 2.1.3 ä¸­å®ç°ï¼‰

# å…³é”®ç®—æ³•
async def _classify_intent(self, query: str) -> str:
    """æ„å›¾åˆ†ç±»
    
    è§„åˆ™å¼•æ“ï¼š
    1. å…³é”®è¯åŒ¹é…ï¼ˆ"æ˜¯ä»€ä¹ˆ"â†’äº‹å®æ€§ï¼‰
    2. æ—¶é—´è¯æ£€æµ‹ï¼ˆ"æœ€è¿‘"â†’æ—¶åºæ€§ï¼‰
    3. å®ä½“å¯†åº¦ï¼ˆâ‰¥3ä¸ªâ†’å…³ç³»æ€§ï¼‰
    """
    if any(kw in query for kw in ["æ˜¯ä»€ä¹ˆ", "å®šä¹‰"]):
        return "factual"
    
    if any(kw in query for kw in ["ä»€ä¹ˆæ—¶å€™", "æœ€è¿‘"]):
        return "temporal"
    
    if any(kw in query for kw in ["å…³ç³»", "å½±å“"]):
        return "relational"
    
    # NER è¾…åŠ©åˆ¤æ–­
    entities = await self.ner.extract(query)
    if len(entities) >= 3:
        return "relational"
    
    return "factual"

# æƒé‡è°ƒæ•´ç­–ç•¥
adjustments = {
    "factual": {"vector": 1.2, "graph": 0.8},    # äº‹å®æ€§åå‘é‡
    "temporal": {"vector": 1.0, "graph": 1.0},   # æ—¶åºæ€§å‡è¡¡
    "relational": {"vector": 0.8, "graph": 1.2}  # å…³ç³»æ€§åå›¾è°±
}
```

#### 3.1.3 é¢„æœŸæ”¶ç›Š

- âœ… å‡†ç¡®ç‡æå‡ï¼š**+15-25%**
- âœ… æ— é¢å¤–æˆæœ¬ï¼ˆè§„åˆ™å¼•æ“ï¼‰
- âœ… é€Ÿåº¦å½±å“ï¼š<10ms

---

### 3.2 ä¸‰å±‚çº§ NER ç®—æ³•

#### 3.2.1 ä¼˜åŒ–ç›®æ ‡

**ç°çŠ¶é—®é¢˜**ï¼š
- å®Œå…¨ä¾èµ– LLM
- æˆæœ¬é«˜ï¼ˆ$0.002/æ¬¡ï¼‰
- é€Ÿåº¦æ…¢ï¼ˆ1-3sï¼‰

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼šä¸‰å±‚çº§çº§è”

#### 3.2.2 ç®—æ³•è®¾è®¡

| å±‚çº§ | æ–¹æ³• | å“åº”æ—¶é—´ | æˆæœ¬ | å‡†ç¡®ç‡ | ç½®ä¿¡åº¦é˜ˆå€¼ |
|------|------|----------|------|--------|-----------|
| Layer 1 | è§„åˆ™ï¼ˆAC è‡ªåŠ¨æœºï¼‰ | <10ms | $0 | 95%ï¼ˆè¯å…¸å†…ï¼‰ | 0.9 |
| Layer 2 | BERTï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰ | <100ms | $0 | 75% | 0.7 |
| Layer 3 | LLMï¼ˆå…œåº•ï¼‰ | 1-3s | $0.002 | 90% | 0.0 |

**æµç¨‹å›¾**ï¼š
```mermaid
graph TD
    A[è¾“å…¥æ–‡æœ¬] --> B[Layer 1: è§„åˆ™åŒ¹é…]
    B -->|ç½®ä¿¡åº¦ â‰¥ 0.9| C[è¿”å›ç»“æœ]
    B -->|ç½®ä¿¡åº¦ < 0.9| D[Layer 2: BERT]
    D -->|ç½®ä¿¡åº¦ â‰¥ 0.7| C
    D -->|ç½®ä¿¡åº¦ < 0.7| E[Layer 3: LLM]
    E --> C
```

#### 3.2.3 é¢„æœŸæ”¶ç›Š

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| **æˆæœ¬** | 100% LLM | 30% LLM | -70% |
| **å¹³å‡é€Ÿåº¦** | 2s | 500ms | +4å€ |
| **å‡†ç¡®ç‡** | 90% | 85-90% | åŸºæœ¬æŒå¹³ |

---

### 3.3 è¯­ä¹‰é‡æ’åºç®—æ³•

#### 3.3.1 ä¼˜åŒ–ç›®æ ‡

**ç°çŠ¶é—®é¢˜**ï¼š
- ç®€å•åŠ æƒèåˆ
- ç¼ºå°‘è¯­ä¹‰ç†è§£

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼šCross-Encoder + MMR

#### 3.3.2 ç®—æ³•è®¾è®¡

##### æ–¹æ¡ˆ Aï¼šåŸºäºè§„åˆ™çš„é‡æ’åºï¼ˆä½æˆæœ¬ï¼‰

```python
# å…³é”®è¯åŒ¹é… + è¯é‡å 
query_words = set(re.findall(r'\w+', query.lower()))
content_words = set(re.findall(r'\w+', result.content.lower()))
overlap = len(query_words & content_words)
boost = overlap / max(len(query_words), 1) * 0.1
result.score += boost
```

##### æ–¹æ¡ˆ Bï¼šLLM é‡æ’åºï¼ˆé«˜æˆæœ¬ã€é«˜å‡†ç¡®ç‡ï¼‰

```python
# LLM æ’åº
prompt = f"""æ ¹æ®æŸ¥è¯¢æ„å›¾ï¼Œå¯¹æ–‡æ¡£æŒ‰ç›¸å…³æ€§æ’åºã€‚

æŸ¥è¯¢ï¼š{query}

æ–‡æ¡£ï¼š
æ–‡æ¡£0: {doc0_content}
æ–‡æ¡£1: {doc1_content}
...

è¿”å›æ’åºåçš„ç¼–å·ï¼š0,2,1,3"""

response = await llm.generate(prompt)
indices = parse_indices(response)
```

#### 3.3.3 MMR å¤šæ ·æ€§æ§åˆ¶

```python
# MMR ç®—æ³•ï¼ˆå·²åœ¨ DiversityFilterStage ä¸­å®ç°ï¼‰
mmr_score = Î» * relevance - (1 - Î») * max_similarity

# Î» = 0.7: å¹³è¡¡ç›¸å…³æ€§å’Œå¤šæ ·æ€§
# Î» = 1.0: å®Œå…¨ç›¸å…³æ€§ä¼˜å…ˆ
# Î» = 0.0: å®Œå…¨å¤šæ ·æ€§ä¼˜å…ˆ
```

#### 3.3.4 é¢„æœŸæ”¶ç›Š

- âœ… å‡†ç¡®ç‡æå‡ï¼š**+10-20%**
- âœ… ç»“æœå¤šæ ·æ€§æå‡ï¼š**+30%**
- âœ… æˆæœ¬ï¼šå–å†³äºæ˜¯å¦å¯ç”¨ LLM

---

### 3.4 é£æ ¼æ¨¡ä»¿ç®—æ³•

#### 3.4.1 ä¼˜åŒ–ç›®æ ‡

**ç°çŠ¶é—®é¢˜**ï¼š
- Prompt å›ºå®š
- ç¼ºå°‘é£æ ¼ç‰¹å¾åº“

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼šç‰¹å¾æå– + åŠ¨æ€ Prompt

#### 3.4.2 ç®—æ³•è®¾è®¡

##### é£æ ¼ç‰¹å¾æå–

```python
class StyleExtractor:
    """é£æ ¼ç‰¹å¾æå–å™¨"""
    
    async def extract(self, documents: List[Document]) -> Dict:
        """æå–ç”¨æˆ·é£æ ¼ç‰¹å¾
        
        Returns:
            {
                "vocabulary": [...],        # é«˜é¢‘è¯æ±‡
                "sentence_patterns": [...], # å¥å¼ç‰¹ç‚¹
                "emotion_tendency": {...},  # æƒ…æ„Ÿå€¾å‘
                "topic_preference": [...]   # è¯é¢˜åå¥½
            }
        """
        # 1. è¯æ±‡åå¥½
        all_words = []
        for doc in documents:
            all_words.extend(jieba.cut(doc.content))
        vocab = Counter(all_words).most_common(100)
        
        # 2. å¥å¼ç‰¹ç‚¹
        sentences = [s for doc in documents for s in re.split(r'[ã€‚ï¼ï¼Ÿ]', doc.content)]
        avg_length = sum(len(s) for s in sentences) / max(len(sentences), 1)
        
        # 3. æƒ…æ„Ÿå€¾å‘
        emotions = [doc.metadata.get("emotion") for doc in documents]
        emotion_dist = Counter(emotions)
        
        return {
            "vocabulary": vocab,
            "avg_sentence_length": avg_length,
            "emotion_distribution": emotion_dist,
            "topic_preference": self._extract_topics(documents)
        }
```

##### åŠ¨æ€ Prompt æ„å»º

```python
async def build_mimic_prompt(
    self, 
    query: str, 
    style: Dict, 
    context: List[str]
) -> str:
    """æ„å»ºæ¨¡ä»¿ Prompt"""
    
    vocab_examples = ", ".join([w for w, _ in style["vocabulary"][:20]])
    
    prompt = f"""ä½ æ­£åœ¨æ¨¡ä»¿ç”¨æˆ·çš„è¯´è¯é£æ ¼ã€‚

ç”¨æˆ·é£æ ¼ç‰¹å¾ï¼š
- å¸¸ç”¨è¯æ±‡ï¼š{vocab_examples}
- å¹³å‡å¥é•¿ï¼š{style["avg_sentence_length"]:.0f}å­—
- æƒ…æ„Ÿå€¾å‘ï¼š{style["emotion_distribution"]}

å†å²å¯¹è¯ç¤ºä¾‹ï¼š
{chr(10).join(context[:3])}

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·ä»¥ç”¨æˆ·çš„é£æ ¼å›ç­”ï¼ˆæ³¨æ„ä½¿ç”¨å¸¸ç”¨è¯æ±‡å’Œå¥å¼ç‰¹ç‚¹ï¼‰ï¼š"""
    
    return prompt
```

#### 3.4.3 é¢„æœŸæ”¶ç›Š

- âœ… é£æ ¼ä¸€è‡´æ€§æå‡ï¼š**+30-40%**
- âœ… ä¸ªæ€§åŒ–ç¨‹åº¦æå‡ï¼š**æ˜¾è‘—**
- âœ… æˆæœ¬ï¼šåŸºæœ¬æŒå¹³ï¼ˆPrompt ç•¥é•¿ï¼‰

---

## 4. æ•°æ®æµè®¾è®¡

### 4.1 æ–‡æ¡£å­˜å‚¨æµç¨‹

```mermaid
graph TD
    A[åŸå§‹æ–‡æ¡£] --> B[TextProcessor æ¸…æ´—]
    B --> C[Chunking åˆ†å—]
    C --> D[NEREngine å®ä½“æå–]
    D --> E[EmotionEngine æƒ…ç»ªè¯†åˆ«]
    E --> F[EmbeddingProcessor å‘é‡åŒ–]
    F --> G{HybridRepository}
    G --> H[FaissAdapter]
    G --> I[FalkorAdapter]
    G --> J[MetadataAdapter]
```

### 4.2 æ£€ç´¢æµç¨‹

```mermaid
graph TD
    A[æŸ¥è¯¢æ–‡æœ¬] --> B[RetrievalPipeline]
    B --> C[VectorRetrievalStage]
    B --> D[GraphRetrievalStage]
    C --> E[FusionStage]
    D --> E
    E --> F[IntentAdaptiveStage]
    F --> G[SemanticRerankStage]
    G --> H[DiversityFilterStage]
    H --> I[è¿”å›ç»“æœ]
```

### 4.3 åˆ†ææµç¨‹

```mermaid
graph TD
    A[æ—¶é—´èŒƒå›´] --> B[AnalyzeEngine æ”¶é›†æ•°æ®]
    B --> C{åˆ†æç±»å‹}
    C -->|è¡Œä¸ºæ¨¡å¼| D[PatternAnalyzer]
    C -->|è¶‹åŠ¿åˆ†æ| E[TrendAnalyzer]
    C -->|æ´å¯Ÿç”Ÿæˆ| F[InsightGenerator]
    D --> G[ç”ŸæˆæŠ¥å‘Š]
    E --> G
    F --> G
```

---

## 5. æ¥å£è®¾è®¡

### 5.1 æ£€ç´¢æ¥å£

```python
# retrieval/factory.py
class RetrievalPipelineFactory:
    """Pipeline å·¥å‚ï¼ˆç®€åŒ–é…ç½®ï¼‰"""
    
    @staticmethod
    def create_basic(vector_retriever) -> RetrievalPipeline:
        """åŸºç¡€é…ç½®ï¼šå‘é‡æ£€ç´¢ + é‡æ’åº"""
        return RetrievalPipeline()\
            .add_stage(VectorRetrievalStage(vector_retriever))\
            .add_stage(SemanticRerankStage())
    
    @staticmethod
    def create_hybrid(
        vector_retriever, 
        graph_retriever, 
        ner_extractor,
        llm_caller
    ) -> RetrievalPipeline:
        """æ··åˆé…ç½®ï¼šå…¨åŠŸèƒ½æ£€ç´¢"""
        return RetrievalPipeline()\
            .add_stage(VectorRetrievalStage(vector_retriever, weight=0.6))\
            .add_stage(GraphRetrievalStage(graph_retriever, weight=0.4))\
            .add_stage(FusionStage())\
            .add_stage(IntentAdaptiveStage(ner_extractor))\
            .add_stage(SemanticRerankStage(llm_caller))\
            .add_stage(DiversityFilterStage(lambda_param=0.7))

# ä½¿ç”¨ç¤ºä¾‹
pipeline = RetrievalPipelineFactory.create_hybrid(
    vector_retriever,
    graph_retriever,
    ner_extractor,
    llm_caller
)

results = await pipeline.execute("æŸ¥è¯¢æ–‡æœ¬", top_k=10)
```

### 5.2 NER æ¥å£

```python
# ner/ner_engine.pyï¼ˆå·²åœ¨ 2.2.3 ä¸­å®šä¹‰ï¼‰

# ä½¿ç”¨ç¤ºä¾‹
ner_engine = NEREngine(
    dictionaries={
        "PERSON": ["å¼ ä¸‰", "æå››"],
        "LOCATION": ["åŒ—äº¬", "ä¸Šæµ·"]
    },
    llm_caller=llm_caller,
    use_bert=False  # å¯é€‰å¯ç”¨ BERT
)

entities = await ner_engine.extract("å¼ ä¸‰åœ¨åŒ—äº¬å·¥ä½œ")
# è¾“å‡ºï¼š[
#   Entity(text="å¼ ä¸‰", type="PERSON", score=0.95),
#   Entity(text="åŒ—äº¬", type="LOCATION", score=0.95)
# ]
```

### 5.3 å­˜å‚¨æ¥å£

```python
# repository/hybrid_repository.pyï¼ˆå·²åœ¨ 2.3.4 ä¸­å®šä¹‰ï¼‰

# ä½¿ç”¨ç¤ºä¾‹
repository = HybridRepository([
    FaissAdapter(faiss_store, embedding_func),
    FalkorAdapter(falkor_store),
    MetadataAdapter(metadata_store)
])

await repository.store(document)
results = await repository.search("æŸ¥è¯¢æ–‡æœ¬", top_k=10)
```

---

## 6. æµ‹è¯•ç­–ç•¥

### 6.1 å•å…ƒæµ‹è¯•

#### 6.1.1 Pipeline æµ‹è¯•

```python
# tests/unit/test_retrieval_pipeline.py
class TestRetrievalPipeline:
    """Pipeline å•å…ƒæµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_single_stage(self):
        """æµ‹è¯•å•é˜¶æ®µæ‰§è¡Œ"""
        mock_stage = Mock(StageBase)
        mock_stage.process.return_value = [
            RetrievalResult(content="test", score=0.9)
        ]
        
        pipeline = RetrievalPipeline().add_stage(mock_stage)
        results = await pipeline.execute("query", top_k=5)
        
        assert len(results) == 1
        assert results[0].score == 0.9
    
    @pytest.mark.asyncio
    async def test_multi_stage(self):
        """æµ‹è¯•å¤šé˜¶æ®µæ‰§è¡Œ"""
        stage1 = VectorRetrievalStage(mock_retriever)
        stage2 = SemanticRerankStage()
        
        pipeline = RetrievalPipeline()\
            .add_stage(stage1)\
            .add_stage(stage2)
        
        results = await pipeline.execute("query", top_k=10)
        assert len(results) <= 10
```

#### 6.1.2 Cascade Inference æµ‹è¯•

```python
# tests/unit/test_cascade_inference.py
class TestCascadeInference:
    """çº§è”æ¨ç†æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_early_return(self):
        """æµ‹è¯•æå‰è¿”å›ï¼ˆé«˜ç½®ä¿¡åº¦ï¼‰"""
        layer1 = Mock(InferenceLayer)
        layer1.infer.return_value = InferenceResult(
            confidence=0.95, data=["entity1"]
        )
        layer2 = Mock(InferenceLayer)  # ä¸åº”è¢«è°ƒç”¨
        
        cascade = CascadeInference()\
            .add_layer(layer1, confidence_threshold=0.9)\
            .add_layer(layer2, confidence_threshold=0.0)
        
        result = await cascade.infer("text")
        
        assert result.confidence == 0.95
        layer2.infer.assert_not_called()  # éªŒè¯æœªè°ƒç”¨
    
    @pytest.mark.asyncio
    async def test_fallback_to_last_layer(self):
        """æµ‹è¯•å…œåº•åˆ°æœ€åä¸€å±‚"""
        layer1 = Mock(InferenceLayer)
        layer1.infer.return_value = InferenceResult(confidence=0.5, data=[])
        layer2 = Mock(InferenceLayer)
        layer2.infer.return_value = InferenceResult(confidence=0.6, data=["entity"])
        
        cascade = CascadeInference()\
            .add_layer(layer1, confidence_threshold=0.9)\
            .add_layer(layer2, confidence_threshold=0.0)
        
        result = await cascade.infer("text")
        
        assert result.confidence == 0.6
        layer2.infer.assert_called_once()
```

### 6.2 é›†æˆæµ‹è¯•

```python
# tests/integration/test_rag_pipeline.py
class TestRAGPipeline:
    """RAG ç«¯åˆ°ç«¯æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_full_retrieval_flow(self):
        """æµ‹è¯•å®Œæ•´æ£€ç´¢æµç¨‹"""
        # 1. å­˜å‚¨æ–‡æ¡£
        doc = Document(
            id="doc1",
            content="æµ‹è¯•å†…å®¹",
            entities=["å®ä½“1"],
            doc_type=DocumentType.WORK_LOG
        )
        await repository.store(doc)
        
        # 2. æ£€ç´¢
        results = await pipeline.execute("æµ‹è¯•æŸ¥è¯¢", top_k=5)
        
        # 3. éªŒè¯
        assert len(results) > 0
        assert results[0].metadata["doc_id"] == "doc1"
```

### 6.3 æ€§èƒ½æµ‹è¯•

```python
# tests/performance/test_benchmark.py
class TestPerformance:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_ner_cost(self):
        """æµ‹è¯• NER æˆæœ¬ä¼˜åŒ–"""
        texts = ["çŸ­æ–‡æœ¬"] * 100 + ["é•¿æ–‡æœ¬" * 100] * 100
        
        start_time = time.time()
        llm_calls = 0
        
        for text in texts:
            result = await ner_engine.extract(text)
            if result.metadata["layer"] == "LLMNER":
                llm_calls += 1
        
        elapsed = time.time() - start_time
        
        # éªŒè¯ï¼šLLM è°ƒç”¨ < 30%
        assert llm_calls / len(texts) < 0.3
        
        # éªŒè¯ï¼šå¹³å‡é€Ÿåº¦ < 500ms
        assert elapsed / len(texts) < 0.5
```

---

## 7. è¿ç§»è®¡åˆ’

### 7.1 Phase 1ï¼šæ ¸å¿ƒæ¡†æ¶ï¼ˆ2å‘¨ï¼‰

| ä»»åŠ¡ | å·¥ä½œé‡ | ä¼˜å…ˆçº§ | è¾“å‡º |
|------|--------|--------|------|
| å®ç° `RetrievalPipeline` | 2äººå¤© | ğŸ”´ é«˜ | `retrieval/pipeline.py` |
| å®ç° `CascadeInference` | 2äººå¤© | ğŸ”´ é«˜ | `core/cascade_inference.py` |
| å®ç° `StorageAdapter` | 1äººå¤© | ğŸ”´ é«˜ | `storage/adapter.py` |
| å®ç° Pipeline Stages | 3äººå¤© | ğŸ”´ é«˜ | `retrieval/stages/` |
| ç¼–å†™å•å…ƒæµ‹è¯• | 2äººå¤© | ğŸ”´ é«˜ | `tests/unit/` |

### 7.2 Phase 2ï¼šç®—æ³•ä¼˜åŒ–ï¼ˆ2å‘¨ï¼‰

| ä»»åŠ¡ | å·¥ä½œé‡ | ä¼˜å…ˆçº§ | è¾“å‡º |
|------|--------|--------|------|
| å®ç°æ„å›¾è‡ªé€‚åº” | 2äººå¤© | ğŸ”´ é«˜ | `IntentAdaptiveStage` |
| å®ç°ä¸‰å±‚çº§ NER | 3äººå¤© | ğŸ”´ é«˜ | `NEREngine` + Layers |
| å®ç°è¯­ä¹‰é‡æ’åº | 2äººå¤© | ğŸŸ  ä¸­ | `SemanticRerankStage` |
| å®ç°é£æ ¼æå– | 2äººå¤© | ğŸŸ  ä¸­ | `StyleExtractor` |
| æ€§èƒ½åŸºå‡†æµ‹è¯• | 1äººå¤© | ğŸŸ  ä¸­ | `tests/performance/` |

### 7.3 Phase 3ï¼šæ¨¡å—é‡æ„ï¼ˆ1å‘¨ï¼‰

| ä»»åŠ¡ | å·¥ä½œé‡ | ä¼˜å…ˆçº§ | è¾“å‡º |
|------|--------|--------|------|
| æ‹†åˆ† `data_processor` | 1äººå¤© | ğŸŸ¡ ä½ | `data_processor/` + `analysis/` |
| åˆ é™¤ `async_processor.py` | 0.5äººå¤© | ğŸŸ¡ ä½ | - |
| åˆ é™¤ `hybrid_retriever.py` | 0.5äººå¤© | ğŸŸ¡ ä½ | - |
| åˆ é™¤ `reranker.py` | 0.5äººå¤© | ğŸŸ¡ ä½ | - |
| æ›´æ–°æ–‡æ¡£ | 1äººå¤© | ğŸŸ¡ ä½ | `README.md` |

### 7.4 è¿ç§»é£é™©

| é£é™© | å½±å“ | åº”å¯¹æªæ–½ |
|------|------|---------|
| Pipeline å¤æ‚åº¦é«˜ | ğŸ”´ é«˜ | æä¾›å·¥å‚æ–¹æ³•ç®€åŒ–é…ç½® |
| Cascade æ€§èƒ½é—®é¢˜ | ğŸŸ  ä¸­ | æ€§èƒ½æµ‹è¯•éªŒè¯ï¼Œä¼˜åŒ–ç½®ä¿¡åº¦é˜ˆå€¼ |
| å­˜å‚¨é€‚é…å™¨å…¼å®¹æ€§ | ğŸŸ  ä¸­ | å……åˆ†çš„é›†æˆæµ‹è¯• |
| å­¦ä¹ æ›²çº¿é™¡å³­ | ğŸŸ¡ ä½ | ç¼–å†™è¯¦ç»†æ–‡æ¡£å’Œç¤ºä¾‹ |

---

## 8. æ–‡ä»¶ç»“æ„å¯¹æ¯”

### 8.1 ä¼˜åŒ–å‰

```
ame/
â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ vector_retriever.py
â”‚   â”œâ”€â”€ graph_retriever.py
â”‚   â”œâ”€â”€ hybrid_retriever.py    # âŒ åˆ é™¤
â”‚   â”œâ”€â”€ reranker.py             # âŒ åˆ é™¤
â”‚   â””â”€â”€ base.py
â”œâ”€â”€ ner/
â”‚   â”œâ”€â”€ simple_ner.py
â”‚   â”œâ”€â”€ llm_ner.py
â”‚   â”œâ”€â”€ hybrid_ner.py           # âŒ é‡æ„
â”‚   â””â”€â”€ base.py
â”œâ”€â”€ data_processor/
â”‚   â”œâ”€â”€ processor.py
â”‚   â”œâ”€â”€ async_processor.py      # âŒ åˆ é™¤
â”‚   â””â”€â”€ analyzer.py             # âŒ ç§»åŠ¨
â””â”€â”€ storage/
    â”œâ”€â”€ faiss_store.py
    â”œâ”€â”€ falkor_store.py
    â””â”€â”€ metadata_store.py
```

### 8.2 ä¼˜åŒ–å

```
ame/
â”œâ”€â”€ core/                       # ğŸ†• æ ¸å¿ƒæ¡†æ¶
â”‚   â”œâ”€â”€ cascade_inference.py
â”‚   â””â”€â”€ inference_layer.py
â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ pipeline.py             # ğŸ†• Pipeline å¼•æ“
â”‚   â”œâ”€â”€ stages/                 # ğŸ†• æ£€ç´¢é˜¶æ®µ
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ vector_stage.py
â”‚   â”‚   â”œâ”€â”€ graph_stage.py
â”‚   â”‚   â”œâ”€â”€ fusion_stage.py
â”‚   â”‚   â”œâ”€â”€ rerank_stage.py
â”‚   â”‚   â”œâ”€â”€ diversity_stage.py
â”‚   â”‚   â””â”€â”€ intent_adaptive_stage.py
â”‚   â”œâ”€â”€ factory.py              # ğŸ†• å·¥å‚æ–¹æ³•
â”‚   â”œâ”€â”€ vector_retriever.py     # ä¿ç•™
â”‚   â”œâ”€â”€ graph_retriever.py      # ä¿ç•™
â”‚   â””â”€â”€ base.py
â”œâ”€â”€ ner/
â”‚   â”œâ”€â”€ ner_engine.py           # ğŸ†• NER å¼•æ“
â”‚   â”œâ”€â”€ layers/                 # ğŸ†• NER å±‚
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ rule_layer.py
â”‚   â”‚   â”œâ”€â”€ bert_layer.py
â”‚   â”‚   â””â”€â”€ llm_layer.py
â”‚   â””â”€â”€ base.py
â”œâ”€â”€ data_processor/             # çº¯æ•°æ®å¤„ç†
â”‚   â”œâ”€â”€ text_processor.py       # ğŸ†•
â”‚   â”œâ”€â”€ file_processor.py       # ğŸ†•
â”‚   â””â”€â”€ embedding_processor.py  # ğŸ†•
â”œâ”€â”€ analysis/                   # ğŸ†• ç‹¬ç«‹åˆ†ææ¨¡å—
â”‚   â”œâ”€â”€ pattern_analyzer.py
â”‚   â”œâ”€â”€ trend_analyzer.py
â”‚   â”œâ”€â”€ insight_generator.py
â”‚   â””â”€â”€ emotion/
â”‚       â”œâ”€â”€ emotion_engine.py   # ğŸ†•
â”‚       â””â”€â”€ layers/
â”‚           â”œâ”€â”€ lexicon_layer.py
â”‚           â”œâ”€â”€ bert_layer.py
â”‚           â””â”€â”€ llm_layer.py
â””â”€â”€ storage/
    â”œâ”€â”€ adapter.py              # ğŸ†• é€‚é…å™¨æ¥å£
    â”œâ”€â”€ adapters/               # ğŸ†• å…·ä½“é€‚é…å™¨
    â”‚   â”œâ”€â”€ faiss_adapter.py
    â”‚   â”œâ”€â”€ falkor_adapter.py
    â”‚   â””â”€â”€ metadata_adapter.py
    â”œâ”€â”€ faiss_store.py          # ä¿ç•™
    â”œâ”€â”€ falkor_store.py         # ä¿ç•™
    â””â”€â”€ metadata_store.py       # ä¿ç•™
```

---

## 9. æ€§èƒ½æŒ‡æ ‡

### 9.1 ä¼˜åŒ–ç›®æ ‡

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| **æ£€ç´¢å‡†ç¡®ç‡** | 70% | 85-95% | +15-25% |
| **API æˆæœ¬** | $1.00/100æ¬¡ | $0.30/100æ¬¡ | -70% |
| **å¹³å‡å“åº”é€Ÿåº¦** | 2-3s | 500ms-1s | +3-5å€ |
| **ä»£ç å¤ç”¨ç‡** | 30% | 100% | +70% |
| **æµ‹è¯•è¦†ç›–ç‡** | 60% | 90% | +30% |

### 9.2 æˆæœ¬åˆ†æ

#### ä¼˜åŒ–å‰ï¼ˆ100 æ¬¡æŸ¥è¯¢ï¼‰

| æ“ä½œ | è°ƒç”¨æ¬¡æ•° | å•ä»· | æ€»æˆæœ¬ |
|------|---------|------|--------|
| NER (LLM) | 100 | $0.002 | $0.20 |
| æ£€ç´¢ (Embedding) | 100 | $0.0001 | $0.01 |
| é‡æ’åº (LLM) | 50 | $0.005 | $0.25 |
| **æ€»è®¡** | - | - | **$0.46** |

#### ä¼˜åŒ–åï¼ˆ100 æ¬¡æŸ¥è¯¢ï¼‰

| æ“ä½œ | è°ƒç”¨æ¬¡æ•° | å•ä»· | æ€»æˆæœ¬ |
|------|---------|------|--------|
| NER (è§„åˆ™/BERT) | 70 | $0 | $0 |
| NER (LLM å…œåº•) | 30 | $0.002 | $0.06 |
| æ£€ç´¢ (Embedding) | 100 | $0.0001 | $0.01 |
| é‡æ’åº (è§„åˆ™) | 80 | $0 | $0 |
| é‡æ’åº (LLM) | 20 | $0.005 | $0.10 |
| **æ€»è®¡** | - | - | **$0.17** |

**æˆæœ¬é™ä½ï¼š63%**

---

## 10. å…³é”®ç±»å›¾

### 10.1 Pipeline æ¶æ„

```mermaid
classDiagram
    class RetrievalPipeline {
        -List~StageBase~ stages
        +add_stage(stage) RetrievalPipeline
        +execute(query, top_k) List~RetrievalResult~
    }
    
    class StageBase {
        <<abstract>>
        +process(query, results, context)* List~RetrievalResult~
        +get_name()* str
    }
    
    class VectorRetrievalStage {
        -VectorRetriever retriever
        -float weight
        +process() List~RetrievalResult~
        +get_name() str
    }
    
    class FusionStage {
        -str fusion_method
        +process() List~RetrievalResult~
        +get_name() str
    }
    
    class IntentAdaptiveStage {
        -NEREngine ner
        +process() List~RetrievalResult~
        -_classify_intent() str
        +get_name() str
    }
    
    RetrievalPipeline o-- StageBase
    StageBase <|-- VectorRetrievalStage
    StageBase <|-- FusionStage
    StageBase <|-- IntentAdaptiveStage
```

### 10.2 Cascade Inference

```mermaid
classDiagram
    class CascadeInference {
        -List~Dict~ layers
        +add_layer(layer, threshold) CascadeInference
        +infer(input_data) InferenceResult
    }
    
    class InferenceLayer {
        <<abstract>>
        +infer(input_data)* InferenceResult
        +get_name()* str
    }
    
    class RuleNERLayer {
        -Dict dictionaries
        +infer(text) InferenceResult
        +get_name() str
    }
    
    class BertNERLayer {
        -Model model
        +infer(text) InferenceResult
        +get_name() str
    }
    
    class LLMNERLayer {
        -LLMCaller llm
        +infer(text) InferenceResult
        -_parse_entities() List~Entity~
        +get_name() str
    }
    
    CascadeInference o-- InferenceLayer
    InferenceLayer <|-- RuleNERLayer
    InferenceLayer <|-- BertNERLayer
    InferenceLayer <|-- LLMNERLayer
```

### 10.3 Storage Adapter

```mermaid
classDiagram
    class StorageAdapter {
        <<abstract>>
        +store(doc)* str
        +search(query, top_k)* List~RetrievalResult~
        +delete(doc_id)* bool
        +get_stats()* Dict
    }
    
    class FaissAdapter {
        -FaissStore store
        -EmbeddingFunc embed
        +store(doc) str
        +search(query, top_k) List~RetrievalResult~
        +delete(doc_id) bool
        +get_stats() Dict
    }
    
    class FalkorAdapter {
        -FalkorStore store
        +store(doc) str
        +search(query, top_k) List~RetrievalResult~
        +delete(doc_id) bool
        +get_stats() Dict
    }
    
    class HybridRepository {
        -List~StorageAdapter~ adapters
        +store(doc) void
        +search(query, top_k) List~RetrievalResult~
        -_merge_results() List~RetrievalResult~
    }
    
    StorageAdapter <|-- FaissAdapter
    StorageAdapter <|-- FalkorAdapter
    HybridRepository o-- StorageAdapter
```
























































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































