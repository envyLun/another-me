# Another Me - é‡æ„å®æ–½æŒ‡å—

æœ¬æ–‡æ¡£æä¾›é‡æ„çš„å…·ä½“å®æ–½æ­¥éª¤å’Œä»£ç ç¤ºä¾‹ã€‚

---

## ğŸ“‹ Phase 1: åŸºç¡€æ¶æ„é‡æ„

### Step 1.1: åˆ›å»ºç»Ÿä¸€æ•°æ®æ¨¡å‹

**æ–‡ä»¶**: `backend/app/models/domain.py`

```python
"""
é¢†åŸŸæ¨¡å‹ - ç»Ÿä¸€çš„æ•°æ®ç»“æ„å®šä¹‰
"""
from enum import Enum
from datetime import datetime
from typing import Dict, Any, Optional, List
from pydantic import BaseModel, Field
import uuid


class DocumentType(str, Enum):
    """æ–‡æ¡£ç±»å‹æšä¸¾"""
    RAG_KNOWLEDGE = "rag_knowledge"
    MEM_CONVERSATION = "mem_conversation"
    MEM_DIARY = "mem_diary"
    MEM_SOCIAL = "mem_social"


class DocumentStatus(str, Enum):
    """æ–‡æ¡£çŠ¶æ€"""
    PROCESSING = "processing"
    ACTIVE = "active"
    ARCHIVED = "archived"
    DELETED = "deleted"


class Document(BaseModel):
    """åŸºç¡€æ–‡æ¡£æ¨¡å‹"""
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    content: str
    doc_type: DocumentType
    source: str
    status: DocumentStatus = DocumentStatus.PROCESSING
    timestamp: datetime
    metadata: Dict[str, Any] = Field(default_factory=dict)
    embedding: Optional[List[float]] = None
    created_at: datetime = Field(default_factory=datetime.now)
    updated_at: datetime = Field(default_factory=datetime.now)
    
    class Config:
        use_enum_values = True
        json_encoders = {
            datetime: lambda v: v.isoformat()
        }


class Knowledge(Document):
    """çŸ¥è¯†æ–‡æ¡£ï¼ˆRAG ä¸“ç”¨ï¼‰"""
    doc_type: DocumentType = DocumentType.RAG_KNOWLEDGE
    tags: List[str] = Field(default_factory=list)
    file_path: Optional[str] = None
    chunk_index: int = 0
    total_chunks: int = 1


class Memory(Document):
    """è®°å¿†æ–‡æ¡£ï¼ˆMEM ä¸“ç”¨ï¼‰"""
    doc_type: DocumentType = DocumentType.MEM_CONVERSATION
    emotion: Optional[str] = None
    importance: float = 0.5
```

### Step 1.2: åˆ›å»ºå…ƒæ•°æ®æ•°æ®åº“

**æ–‡ä»¶**: `backend/app/core/database.py`

```python
"""
å…ƒæ•°æ®æ•°æ®åº“ç®¡ç†ï¼ˆSQLiteï¼‰
"""
import sqlite3
from pathlib import Path
from typing import Dict, List, Optional, Any
import json
from datetime import datetime
from app.core.logger import get_logger

logger = get_logger(__name__)


class MetadataDB:
    """å…ƒæ•°æ®æ•°æ®åº“"""
    
    def __init__(self, db_path: str = "./data/metadata.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self._init_db()
    
    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS documents (
                    id TEXT PRIMARY KEY,
                    doc_type TEXT NOT NULL,
                    source TEXT,
                    status TEXT,
                    timestamp DATETIME,
                    created_at DATETIME,
                    updated_at DATETIME,
                    metadata TEXT
                )
            """)
            
            # åˆ›å»ºç´¢å¼•
            conn.execute("CREATE INDEX IF NOT EXISTS idx_doc_type ON documents(doc_type)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_source ON documents(source)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_status ON documents(status)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_timestamp ON documents(timestamp)")
            
            conn.commit()
            logger.info("Metadata database initialized")
    
    def insert(self, doc: Dict[str, Any]) -> bool:
        """æ’å…¥æ–‡æ¡£å…ƒæ•°æ®"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT INTO documents 
                (id, doc_type, source, status, timestamp, created_at, updated_at, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                doc["id"],
                doc["doc_type"],
                doc["source"],
                doc.get("status", "processing"),
                doc.get("timestamp"),
                doc.get("created_at"),
                doc.get("updated_at"),
                json.dumps(doc.get("metadata", {}))
            ))
            conn.commit()
        return True
    
    def get(self, doc_id: str) -> Optional[Dict]:
        """è·å–æ–‡æ¡£å…ƒæ•°æ®"""
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("SELECT * FROM documents WHERE id = ?", (doc_id,))
            row = cursor.fetchone()
            if row:
                return dict(row)
        return None
    
    def list(
        self, 
        doc_type: Optional[str] = None,
        source: Optional[str] = None,
        status: Optional[str] = None,
        limit: int = 100,
        offset: int = 0
    ) -> List[Dict]:
        """åˆ—è¡¨æŸ¥è¯¢"""
        query = "SELECT * FROM documents WHERE 1=1"
        params = []
        
        if doc_type:
            query += " AND doc_type = ?"
            params.append(doc_type)
        if source:
            query += " AND source LIKE ?"
            params.append(f"%{source}%")
        if status:
            query += " AND status = ?"
            params.append(status)
        
        query += " ORDER BY created_at DESC LIMIT ? OFFSET ?"
        params.extend([limit, offset])
        
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute(query, params)
            return [dict(row) for row in cursor.fetchall()]
    
    def update(self, doc_id: str, updates: Dict) -> bool:
        """æ›´æ–°æ–‡æ¡£å…ƒæ•°æ®"""
        updates["updated_at"] = datetime.now().isoformat()
        
        set_clause = ", ".join([f"{k} = ?" for k in updates.keys()])
        query = f"UPDATE documents SET {set_clause} WHERE id = ?"
        params = list(updates.values()) + [doc_id]
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute(query, params)
            conn.commit()
        return True
    
    def delete(self, doc_id: str) -> bool:
        """åˆ é™¤æ–‡æ¡£å…ƒæ•°æ®"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("DELETE FROM documents WHERE id = ?", (doc_id,))
            conn.commit()
        return True
    
    def count(self, doc_type: Optional[str] = None) -> int:
        """ç»Ÿè®¡æ–‡æ¡£æ•°é‡"""
        query = "SELECT COUNT(*) FROM documents"
        params = []
        
        if doc_type:
            query += " WHERE doc_type = ?"
            params.append(doc_type)
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(query, params)
            return cursor.fetchone()[0]
```

### Step 1.3: å®ç° Repository å±‚

**æ–‡ä»¶**: `backend/app/repositories/base.py`

```python
"""
Repository åŸºç±» - æ•°æ®è®¿é—®å±‚æŠ½è±¡
"""
from abc import ABC, abstractmethod
from typing import List, Optional, Dict, Any
from app.models.domain import Document
from app.models.responses import PaginatedResponse


class BaseRepository(ABC):
    """ä»“åº“åŸºç±»"""
    
    @abstractmethod
    async def create(self, doc: Document) -> Document:
        """åˆ›å»ºæ–‡æ¡£"""
        pass
    
    @abstractmethod
    async def get(self, doc_id: str) -> Optional[Document]:
        """è·å–å•ä¸ªæ–‡æ¡£"""
        pass
    
    @abstractmethod
    async def list(
        self,
        filters: Optional[Dict[str, Any]] = None,
        page: int = 1,
        page_size: int = 20
    ) -> PaginatedResponse[Document]:
        """åˆ†é¡µåˆ—è¡¨"""
        pass
    
    @abstractmethod
    async def update(self, doc_id: str, updates: Dict[str, Any]) -> Document:
        """æ›´æ–°æ–‡æ¡£"""
        pass
    
    @abstractmethod
    async def delete(self, doc_id: str) -> bool:
        """åˆ é™¤æ–‡æ¡£"""
        pass
    
    @abstractmethod
    async def search(
        self,
        query: str,
        filters: Optional[Dict[str, Any]] = None,
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """å‘é‡æ£€ç´¢"""
        pass
```

**æ–‡ä»¶**: `backend/app/repositories/rag_repository.py`

```python
"""
RAG Repository - çŸ¥è¯†åº“æ•°æ®è®¿é—®
"""
from typing import List, Optional, Dict, Any
from app.repositories.base import BaseRepository
from app.models.domain import Knowledge, DocumentType, DocumentStatus
from app.models.responses import PaginatedResponse
from app.core.database import MetadataDB
from ame.vector_store.base import VectorStoreBase
from app.core.logger import get_logger

logger = get_logger(__name__)


class RAGRepository(BaseRepository):
    """RAG æ•°æ®ä»“åº“"""
    
    def __init__(self, vector_store: VectorStoreBase, metadata_db: MetadataDB):
        self.vector_store = vector_store
        self.metadata_db = metadata_db
    
    async def create(self, doc: Knowledge) -> Knowledge:
        """åˆ›å»ºçŸ¥è¯†æ–‡æ¡£"""
        # 1. ä¿å­˜åˆ°å‘é‡åº“ï¼ˆè‡ªåŠ¨ç”Ÿæˆ embeddingï¼‰
        await self.vector_store.add_documents([{
            "id": doc.id,
            "content": doc.content,
            "metadata": {
                "doc_type": doc.doc_type,
                "source": doc.source,
                "timestamp": doc.timestamp.isoformat(),
                "tags": doc.tags,
                **doc.metadata
            }
        }])
        
        # 2. ä¿å­˜å…ƒæ•°æ®åˆ°æ•°æ®åº“
        self.metadata_db.insert({
            "id": doc.id,
            "doc_type": doc.doc_type,
            "source": doc.source,
            "status": doc.status,
            "timestamp": doc.timestamp.isoformat(),
            "created_at": doc.created_at.isoformat(),
            "updated_at": doc.updated_at.isoformat(),
            "metadata": {
                "tags": doc.tags,
                "file_path": doc.file_path,
                "chunk_index": doc.chunk_index,
                "total_chunks": doc.total_chunks,
                **doc.metadata
            }
        })
        
        logger.info(f"Created knowledge document: {doc.id}")
        return doc
    
    async def get(self, doc_id: str) -> Optional[Knowledge]:
        """è·å–çŸ¥è¯†æ–‡æ¡£"""
        # ä»å…ƒæ•°æ®åº“è·å–
        metadata = self.metadata_db.get(doc_id)
        if not metadata:
            return None
        
        # ä»å‘é‡åº“è·å–å†…å®¹
        vector_result = await self.vector_store.get_by_id(doc_id)
        
        # ç»„åˆè¿”å›
        return Knowledge(
            id=metadata["id"],
            content=vector_result.get("content", ""),
            source=metadata["source"],
            status=metadata["status"],
            timestamp=metadata["timestamp"],
            tags=metadata.get("metadata", {}).get("tags", []),
            file_path=metadata.get("metadata", {}).get("file_path"),
            chunk_index=metadata.get("metadata", {}).get("chunk_index", 0),
            total_chunks=metadata.get("metadata", {}).get("total_chunks", 1),
            created_at=metadata["created_at"],
            updated_at=metadata["updated_at"]
        )
    
    async def list(
        self,
        filters: Optional[Dict[str, Any]] = None,
        page: int = 1,
        page_size: int = 20
    ) -> PaginatedResponse[Knowledge]:
        """åˆ†é¡µåˆ—è¡¨"""
        filters = filters or {}
        offset = (page - 1) * page_size
        
        # ä»å…ƒæ•°æ®åº“æŸ¥è¯¢
        results = self.metadata_db.list(
            doc_type=DocumentType.RAG_KNOWLEDGE,
            source=filters.get("source"),
            status=filters.get("status"),
            limit=page_size,
            offset=offset
        )
        
        # è½¬æ¢ä¸º Knowledge å¯¹è±¡
        knowledge_list = []
        for metadata in results:
            knowledge = await self.get(metadata["id"])
            if knowledge:
                knowledge_list.append(knowledge)
        
        # è®¡ç®—æ€»æ•°
        total = self.metadata_db.count(doc_type=DocumentType.RAG_KNOWLEDGE)
        
        return PaginatedResponse(
            data=knowledge_list,
            pagination={
                "page": page,
                "page_size": page_size,
                "total": total,
                "total_pages": (total + page_size - 1) // page_size
            }
        )
    
    async def update(self, doc_id: str, updates: Dict[str, Any]) -> Knowledge:
        """æ›´æ–°çŸ¥è¯†æ–‡æ¡£"""
        # æ›´æ–°å…ƒæ•°æ®
        self.metadata_db.update(doc_id, updates)
        
        # å¦‚æœæ›´æ–°äº†å†…å®¹ï¼Œæ›´æ–°å‘é‡åº“
        if "content" in updates:
            await self.vector_store.update_document(doc_id, updates["content"])
        
        # è¿”å›æ›´æ–°åçš„æ–‡æ¡£
        return await self.get(doc_id)
    
    async def delete(self, doc_id: str) -> bool:
        """åˆ é™¤çŸ¥è¯†æ–‡æ¡£"""
        # ä»å‘é‡åº“åˆ é™¤
        await self.vector_store.delete_documents([doc_id])
        
        # ä»å…ƒæ•°æ®åº“åˆ é™¤
        self.metadata_db.delete(doc_id)
        
        logger.info(f"Deleted knowledge document: {doc_id}")
        return True
    
    async def search(
        self,
        query: str,
        filters: Optional[Dict[str, Any]] = None,
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """å‘é‡æ£€ç´¢"""
        results = await self.vector_store.search(
            query=query,
            top_k=top_k,
            filters=filters
        )
        return results
```

---

## ğŸ“‹ Phase 2: Service å±‚é‡æ„

### Step 2.1: é‡å†™ RAGService

**æ–‡ä»¶**: `backend/app/services/rag_service.py`

```python
"""
RAG Service - çŸ¥è¯†åº“ä¸šåŠ¡é€»è¾‘
"""
from typing import List, Optional, Dict, Any
from fastapi import UploadFile
from pathlib import Path
import shutil
from datetime import datetime

from app.models.domain import Knowledge, DocumentStatus
from app.models.responses import PaginatedResponse, SearchResult, QAResponse
from app.repositories.rag_repository import RAGRepository
from ame.data_processor.processor import DataProcessor
from ame.rag.qa_generator import QAGenerator  # éœ€è¦æ–°å»º
from app.core.config import get_settings
from app.core.logger import get_logger
from app.core.exceptions import DocumentNotFoundError, ValidationError

logger = get_logger(__name__)


class RAGService:
    """RAG ä¸šåŠ¡æœåŠ¡"""
    
    def __init__(
        self,
        repository: RAGRepository,
        data_processor: DataProcessor,
        qa_generator: QAGenerator
    ):
        self.repo = repository
        self.processor = data_processor
        self.qa = qa_generator
        self.settings = get_settings()
    
    async def create_knowledge(
        self,
        file: UploadFile,
        tags: List[str] = None,
        metadata: Dict[str, Any] = None
    ) -> Knowledge:
        """
        åˆ›å»ºçŸ¥è¯†æ–‡æ¡£ï¼ˆä»æ–‡ä»¶ä¸Šä¼ ï¼‰
        
        ä¸šåŠ¡æµç¨‹:
        1. éªŒè¯æ–‡ä»¶æ ¼å¼å’Œå¤§å°
        2. ä¿å­˜æ–‡ä»¶åˆ°æœ¬åœ°
        3. è§£ææ–‡ä»¶å†…å®¹
        4. åˆ†å—å¤„ç†
        5. ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå‘é‡åŒ–ï¼‰
        """
        logger.info(f"Creating knowledge from file: {file.filename}")
        
        # 1. éªŒè¯
        file_ext = Path(file.filename).suffix.lower()
        if file_ext not in self.settings.ALLOWED_EXTENSIONS:
            raise ValidationError(f"File type {file_ext} not allowed")
        
        # 2. ä¿å­˜æ–‡ä»¶
        file_path = await self._save_upload_file(file)
        
        try:
            # 3. è§£ææ–‡ä»¶
            documents = await self.processor.process_file(str(file_path))
            
            if not documents:
                raise ValidationError("No content extracted from file")
            
            # 4. åˆ›å»ºçŸ¥è¯†æ–‡æ¡£ï¼ˆåˆ†å—ï¼‰
            knowledge_list = []
            total_chunks = len(documents)
            
            for idx, doc_data in enumerate(documents):
                knowledge = Knowledge(
                    content=doc_data["content"],
                    source=file.filename,
                    timestamp=doc_data.get("timestamp", datetime.now()),
                    tags=tags or [],
                    file_path=str(file_path),
                    chunk_index=idx,
                    total_chunks=total_chunks,
                    metadata=metadata or {},
                    status=DocumentStatus.PROCESSING
                )
                
                # 5. ä¿å­˜åˆ°ä»“åº“
                saved = await self.repo.create(knowledge)
                knowledge_list.append(saved)
            
            # 6. æ›´æ–°çŠ¶æ€ä¸º ACTIVE
            for k in knowledge_list:
                await self.repo.update(k.id, {"status": DocumentStatus.ACTIVE})
            
            logger.info(f"Created {len(knowledge_list)} knowledge chunks")
            
            # è¿”å›ç¬¬ä¸€ä¸ªåˆ†å—
            return knowledge_list[0]
            
        except Exception as e:
            # æ¸…ç†æ–‡ä»¶
            if file_path.exists():
                file_path.unlink()
            raise
    
    async def get_knowledge(self, knowledge_id: str) -> Knowledge:
        """è·å–çŸ¥è¯†æ–‡æ¡£"""
        knowledge = await self.repo.get(knowledge_id)
        if not knowledge:
            raise DocumentNotFoundError(knowledge_id)
        return knowledge
    
    async def list_knowledge(
        self,
        filters: Optional[Dict[str, Any]] = None,
        page: int = 1,
        page_size: int = 20
    ) -> PaginatedResponse[Knowledge]:
        """åˆ—è¡¨æŸ¥è¯¢ï¼ˆåˆ†é¡µï¼‰"""
        return await self.repo.list(filters, page, page_size)
    
    async def update_knowledge(
        self,
        knowledge_id: str,
        updates: Dict[str, Any]
    ) -> Knowledge:
        """æ›´æ–°çŸ¥è¯†æ–‡æ¡£"""
        # éªŒè¯æ–‡æ¡£å­˜åœ¨
        await self.get_knowledge(knowledge_id)
        
        # æ›´æ–°
        return await self.repo.update(knowledge_id, updates)
    
    async def delete_knowledge(self, knowledge_id: str) -> bool:
        """åˆ é™¤çŸ¥è¯†æ–‡æ¡£"""
        await self.get_knowledge(knowledge_id)
        return await self.repo.delete(knowledge_id)
    
    async def search_knowledge(
        self,
        query: str,
        filters: Optional[Dict[str, Any]] = None,
        top_k: int = 5
    ) -> List[SearchResult]:
        """æ£€ç´¢çŸ¥è¯†"""
        results = await self.repo.search(query, filters, top_k)
        
        return [
            SearchResult(
                content=r.get("content"),
                score=r.get("score", 0.0),
                metadata=r.get("metadata", {})
            )
            for r in results
        ]
    
    async def ask_question(
        self,
        question: str,
        context: Optional[str] = None
    ) -> QAResponse:
        """æ™ºèƒ½é—®ç­”ï¼ˆéæµå¼ï¼‰"""
        # 1. æ£€ç´¢ç›¸å…³çŸ¥è¯†
        knowledge = await self.search_knowledge(question, top_k=5)
        
        # 2. ç”Ÿæˆç­”æ¡ˆ
        answer = await self.qa.generate_answer(
            question=question,
            context=context,
            knowledge=knowledge
        )
        
        return QAResponse(
            question=question,
            answer=answer,
            sources=[k.metadata for k in knowledge]
        )
    
    async def ask_question_stream(
        self,
        question: str,
        context: Optional[str] = None
    ):
        """æ™ºèƒ½é—®ç­”ï¼ˆæµå¼ï¼‰"""
        # 1. æ£€ç´¢
        knowledge = await self.search_knowledge(question, top_k=5)
        
        # 2. æµå¼ç”Ÿæˆ
        async for chunk in self.qa.generate_answer_stream(
            question=question,
            context=context,
            knowledge=knowledge
        ):
            yield chunk
    
    async def _save_upload_file(self, file: UploadFile) -> Path:
        """ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶"""
        upload_dir = self.settings.UPLOADS_DIR / "rag"
        upload_dir.mkdir(parents=True, exist_ok=True)
        
        file_path = upload_dir / f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{file.filename}"
        
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        return file_path


# ä¾èµ–æ³¨å…¥
_rag_service: Optional[RAGService] = None

def get_rag_service() -> RAGService:
    global _rag_service
    if _rag_service is None:
        from app.repositories.rag_repository import RAGRepository
        from app.core.database import MetadataDB
        from ame.vector_store.factory import VectorStoreFactory
        from ame.data_processor.processor import DataProcessor
        from ame.rag.qa_generator import QAGenerator
        
        settings = get_settings()
        
        # åˆ›å»ºä¾èµ–
        vector_store = VectorStoreFactory.create(
            store_type=settings.VECTOR_STORE_TYPE,
            db_path=str(settings.RAG_VECTOR_STORE_PATH)
        )
        metadata_db = MetadataDB()
        repository = RAGRepository(vector_store, metadata_db)
        data_processor = DataProcessor()
        qa_generator = QAGenerator()  # éœ€è¦å®ç°
        
        _rag_service = RAGService(repository, data_processor, qa_generator)
    
    return _rag_service
```

---

## ğŸ“‹ Phase 3: API å±‚æ›´æ–°

### Step 3.1: æ›´æ–° RAG API

**æ–‡ä»¶**: `backend/app/api/v1/rag.py`

```python
"""
RAG API ç«¯ç‚¹
"""
from fastapi import APIRouter, UploadFile, File, Depends, Query
from typing import List, Optional

from app.services.rag_service import RAGService, get_rag_service
from app.models.requests import SearchRequest, QARequest
from app.models.responses import (
    KnowledgeResponse,
    PaginatedResponse,
    SearchResponse,
    QAResponse
)

router = APIRouter()


@router.post("/knowledge", response_model=KnowledgeResponse)
async def create_knowledge(
    file: UploadFile = File(...),
    tags: Optional[str] = Query(None),  # é€—å·åˆ†éš”
    service: RAGService = Depends(get_rag_service)
):
    """ä¸Šä¼ çŸ¥è¯†æ–‡æ¡£"""
    tag_list = tags.split(",") if tags else []
    knowledge = await service.create_knowledge(file, tags=tag_list)
    return KnowledgeResponse(success=True, data=knowledge)


@router.get("/knowledge", response_model=PaginatedResponse)
async def list_knowledge(
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100),
    source: Optional[str] = Query(None),
    status: Optional[str] = Query(None),
    service: RAGService = Depends(get_rag_service)
):
    """çŸ¥è¯†åˆ—è¡¨ï¼ˆåˆ†é¡µï¼‰"""
    filters = {}
    if source:
        filters["source"] = source
    if status:
        filters["status"] = status
    
    result = await service.list_knowledge(filters, page, page_size)
    return result


@router.get("/knowledge/{knowledge_id}", response_model=KnowledgeResponse)
async def get_knowledge(
    knowledge_id: str,
    service: RAGService = Depends(get_rag_service)
):
    """è·å–çŸ¥è¯†è¯¦æƒ…"""
    knowledge = await service.get_knowledge(knowledge_id)
    return KnowledgeResponse(success=True, data=knowledge)


@router.delete("/knowledge/{knowledge_id}")
async def delete_knowledge(
    knowledge_id: str,
    service: RAGService = Depends(get_rag_service)
):
    """åˆ é™¤çŸ¥è¯†"""
    success = await service.delete_knowledge(knowledge_id)
    return {"success": success}


@router.post("/search", response_model=SearchResponse)
async def search_knowledge(
    request: SearchRequest,
    service: RAGService = Depends(get_rag_service)
):
    """æ£€ç´¢çŸ¥è¯†"""
    results = await service.search_knowledge(
        query=request.query,
        top_k=request.top_k
    )
    return SearchResponse(success=True, data=results)


@router.post("/ask", response_model=QAResponse)
async def ask_question(
    request: QARequest,
    service: RAGService = Depends(get_rag_service)
):
    """æ™ºèƒ½é—®ç­”"""
    response = await service.ask_question(
        question=request.question,
        context=request.context
    )
    return response
```

---

## ğŸ“‹ æ£€æŸ¥æ¸…å•

### Phase 1 å®Œæˆæ ‡å‡†

- [ ] `domain.py` åˆ›å»ºå®Œæˆ
- [ ] `database.py` å®ç°å¹¶æµ‹è¯•
- [ ] `BaseRepository` å®šä¹‰å®Œæˆ
- [ ] `RAGRepository` å’Œ `MEMRepository` å®ç°
- [ ] æ•°æ®åº“è¿ç§»è„šæœ¬ç¼–å†™
- [ ] å•å…ƒæµ‹è¯•ç¼–å†™

### Phase 2 å®Œæˆæ ‡å‡†

- [ ] `RAGService` é‡æ„å®Œæˆ
- [ ] `MEMService` é‡æ„å®Œæˆ
- [ ] æ‰€æœ‰ CRUD åŠŸèƒ½å®ç°
- [ ] é”™è¯¯å¤„ç†å®Œå–„
- [ ] ä¸šåŠ¡é€»è¾‘æµ‹è¯•é€šè¿‡

### Phase 3 å®Œæˆæ ‡å‡†

- [ ] æ‰€æœ‰ API ç«¯ç‚¹æ›´æ–°
- [ ] API æ–‡æ¡£æ›´æ–°
- [ ] å‰ç«¯ API å®¢æˆ·ç«¯æ›´æ–°
- [ ] é›†æˆæµ‹è¯•é€šè¿‡

---

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **æ•°æ®å¤‡ä»½**: é‡æ„å‰å¤‡ä»½ç°æœ‰å‘é‡æ•°æ®
2. **å‘åå…¼å®¹**: ä¿ç•™æ—§ API ä¸€æ®µæ—¶é—´
3. **æ¸è¿›å¼è¿ç§»**: å…ˆå®Œæˆ RAGï¼Œå†åš MEM
4. **æµ‹è¯•é©±åŠ¨**: æ¯ä¸ªæ¨¡å—å…ˆå†™æµ‹è¯•
5. **æ–‡æ¡£åŒæ­¥**: ä»£ç å’Œæ–‡æ¡£åŒæ­¥æ›´æ–°
