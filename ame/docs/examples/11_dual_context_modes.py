"""
ç¤ºä¾‹ 11: åŒæ¨¡å¼ä¸Šä¸‹æ–‡ç®¡ç†

æ¼”ç¤º SESSION å’Œ DOCUMENT ä¸¤ç§ä¸Šä¸‹æ–‡ç®¡ç†æ¨¡å¼çš„ä½¿ç”¨åœºæ™¯ã€‚

åœºæ™¯1 - SESSION æ¨¡å¼ï¼ˆä¼šè¯å‹ï¼‰:
- ç”¨æˆ·å¤šè½®å¯¹è¯
- ä¿ç•™å®Œæ•´å†å²
- å¯¹è¯ç»“æŸæ—¶å¯¼å‡ºåˆ°å›¾è°±æ•°æ®åº“

åœºæ™¯2 - DOCUMENT æ¨¡å¼ï¼ˆæ–‡æ¡£å‹ï¼‰:
- å¤„ç†é•¿æ–‡æœ¬ï¼ˆPDFã€TXTç­‰ï¼‰
- è‡ªåŠ¨é™é»˜å‹ç¼©
- ä¿ç•™å…³é”®ä¿¡æ¯ç”¨äºå¯¼å‡º
"""

import asyncio
import os
from ame.foundation.llm import OpenAICaller, ContextMode


async def demo_session_mode():
    """æ¼”ç¤ºä¼šè¯æ¨¡å¼ï¼ˆSESSIONï¼‰"""
    print("\n" + "=" * 60)
    print("ä¼šè¯æ¨¡å¼ï¼ˆSESSIONï¼‰æ¼”ç¤º")
    print("=" * 60)
    
    llm = OpenAICaller(
        api_key=os.getenv("OPENAI_API_KEY", "sk-..."),
        model="gpt-3.5-turbo",
        max_context_tokens=2000  # è®¾ç½®è¾ƒå°çš„é™åˆ¶ç”¨äºæ¼”ç¤º
    )
    
    # åˆ›å»ºä¼šè¯æ¨¡å¼çš„å¯¹è¯
    conversation = llm.create_conversation(
        system_prompt="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œä¸“æ³¨äºå¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜ã€‚",
        mode=ContextMode.SESSION
    )
    
    print(f"\nâœ… åˆ›å»ºä¼šè¯ (æ¨¡å¼: {conversation.mode.value})")
    print(f"ğŸ“Š æœ€å¤§ä¸Šä¸‹æ–‡: {llm.max_context_tokens} tokens")
    
    # æ¨¡æ‹Ÿå¤šè½®å¯¹è¯
    questions = [
        "ä½ å¥½ï¼Œæˆ‘æƒ³å­¦ä¹  Python",
        "ä»å“ªé‡Œå¼€å§‹æ¯”è¾ƒå¥½ï¼Ÿ",
        "æœ‰ä»€ä¹ˆå¥½çš„ä¹¦ç±æ¨èå—ï¼Ÿ",
        "æˆ‘åº”è¯¥å…ˆå­¦ä»€ä¹ˆï¼Ÿ",
        "è°¢è°¢ä½ çš„å»ºè®®ï¼"
    ]
    
    print("\n" + "-" * 60)
    print("å¼€å§‹å¤šè½®å¯¹è¯:")
    print("-" * 60)
    
    for i, question in enumerate(questions, 1):
        print(f"\n[è½®æ¬¡ {i}]")
        print(f"ğŸ‘¤ ç”¨æˆ·: {question}")
        
        # æ ‡è®°é‡è¦æ¶ˆæ¯ï¼ˆå¯é€‰ï¼‰
        is_important = "æ¨è" in question or "å¼€å§‹" in question
        
        response = await llm.chat_with_history(
            conversation=conversation,
            user_message=question,
            temperature=0.7
        )
        
        # å¦‚æœæ˜¯é‡è¦é—®é¢˜ï¼Œæ ‡è®°å›å¤ä¸ºé‡è¦
        if is_important:
            # è·å–æœ€åä¸€æ¡æ¶ˆæ¯å¹¶æ ‡è®°ä¸ºé‡è¦
            if conversation.messages:
                conversation.messages[-1].metadata["important"] = True
                print("â­ å·²æ ‡è®°ä¸ºé‡è¦æ¶ˆæ¯")
        
        print(f"ğŸ¤– AI: {response.content[:150]}...")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = conversation.get_compression_stats()
        print(f"ğŸ“Š å½“å‰æ¶ˆæ¯æ•°: {stats['active_messages']} (å½’æ¡£: {stats['archived_messages']})")
    
    # å¯¹è¯ç»“æŸï¼Œå¯¼å‡ºåˆ°å›¾è°±
    print("\n" + "-" * 60)
    print("å¯¹è¯ç»“æŸï¼Œå‡†å¤‡å¯¼å‡ºåˆ°å›¾è°±æ•°æ®åº“...")
    print("-" * 60)
    
    # æ–¹æ³•1ï¼šå¯¼å‡ºå…³é”®ä¿¡æ¯ï¼ˆæ ¹æ® mode è‡ªåŠ¨é€‰æ‹©ç­–ç•¥ï¼‰
    important_data = conversation.export_important()
    
    print(f"\nğŸ“Š å¯¼å‡ºå…³é”®ä¿¡æ¯ï¼ˆSESSION æ¨¡å¼ï¼‰:")
    print(f"  - æ¨¡å¼: {important_data['mode']}")
    print(f"  - æ€»å¯¹è¯æ•°: {important_data['total_conversations']}")
    print(f"  - é‡è¦æ¶ˆæ¯æ•°: {important_data['important_count']}")
    print(f"  - å¯¼å‡ºå†…å®¹: {len(important_data['export_content'])} æ¡")
    
    print(f"\nğŸ“‹ å¯¼å‡ºçš„å…³é”®æ¶ˆæ¯:")
    for i, msg in enumerate(important_data['export_content'][:3], 1):
        important_tag = " â­" if msg.get('important') else ""
        print(f"  {i}. [{msg['role']}] {msg['content'][:50]}...{important_tag}")
    
    # æ–¹æ³•2ï¼šæ¸…ç©ºå¹¶å¯¼å‡ºï¼ˆå¯¹è¯ç»“ææ—¶ä½¿ç”¨ï¼‰
    # graph_data = conversation.clear_and_export()
    
    return important_data


async def demo_document_mode():
    """æ¼”ç¤ºæ–‡æ¡£æ¨¡å¼ï¼ˆDOCUMENTï¼‰"""
    print("\n" + "=" * 60)
    print("æ–‡æ¡£æ¨¡å¼ï¼ˆDOCUMENTï¼‰æ¼”ç¤º")
    print("=" * 60)
    
    llm = OpenAICaller(
        api_key=os.getenv("OPENAI_API_KEY", "sk-..."),
        model="gpt-3.5-turbo",
        max_context_tokens=1500  # è¾ƒå°çš„é™åˆ¶ï¼Œä¾¿äºè§¦å‘å‹ç¼©
    )
    
    # åˆ›å»ºæ–‡æ¡£æ¨¡å¼çš„å¯¹è¯
    doc_conversation = llm.create_conversation(
        system_prompt="è¯·åˆ†æä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚",
        mode=ContextMode.DOCUMENT
    )
    
    print(f"\nâœ… åˆ›å»ºæ–‡æ¡£å¤„ç†ä¼šè¯ (æ¨¡å¼: {doc_conversation.mode.value})")
    print(f"ğŸ“Š æœ€å¤§ä¸Šä¸‹æ–‡: {llm.max_context_tokens} tokens")
    print(f"ğŸ’¡ æ–‡æ¡£æ¨¡å¼ä¼šè‡ªåŠ¨é™é»˜å‹ç¼©é•¿æ–‡æœ¬")
    
    # æ¨¡æ‹Ÿå¤„ç†é•¿æ–‡æ¡£
    print("\n" + "-" * 60)
    print("å¼€å§‹å¤„ç†é•¿æ–‡æ¡£:")
    print("-" * 60)
    
    # æ¨¡æ‹Ÿåˆ†æ®µä¸Šä¼ å¤§æ–‡æ¡£
    document_chunks = [
        """
        ç¬¬ä¸€éƒ¨åˆ†ï¼šPython ç®€ä»‹
        Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œç”±Guido van Rossumäº1989å¹´åˆ›å»ºã€‚
        å®ƒå…·æœ‰ç®€æ´çš„è¯­æ³•ã€å¼ºå¤§çš„åŠŸèƒ½å’Œä¸°å¯Œçš„åº“æ”¯æŒã€‚
        Pythonå¹¿æ³›åº”ç”¨äºWebå¼€å‘ã€æ•°æ®åˆ†æã€äººå·¥æ™ºèƒ½ç­‰é¢†åŸŸã€‚
        """,
        """
        ç¬¬äºŒéƒ¨åˆ†ï¼šPython ç‰¹æ€§
        1. æ˜“å­¦æ˜“ç”¨ï¼šè¯­æ³•ç®€æ´æ˜äº†ï¼Œé€‚åˆåˆå­¦è€…
        2. è·¨å¹³å°ï¼šæ”¯æŒWindowsã€Linuxã€macOSç­‰å¤šä¸ªæ“ä½œç³»ç»Ÿ
        3. ä¸°å¯Œçš„åº“ï¼šæ‹¥æœ‰å¤§é‡ç¬¬ä¸‰æ–¹åº“å’Œæ¡†æ¶
        4. åŠ¨æ€ç±»å‹ï¼šæ— éœ€å£°æ˜å˜é‡ç±»å‹
        5. é¢å‘å¯¹è±¡ï¼šæ”¯æŒé¢å‘å¯¹è±¡ç¼–ç¨‹èŒƒå¼
        """,
        """
        ç¬¬ä¸‰éƒ¨åˆ†ï¼šPython åº”ç”¨é¢†åŸŸ
        - Webå¼€å‘ï¼šDjangoã€Flaskç­‰æ¡†æ¶
        - æ•°æ®ç§‘å­¦ï¼šNumPyã€Pandasã€Matplotlib
        - äººå·¥æ™ºèƒ½ï¼šTensorFlowã€PyTorchã€scikit-learn
        - è‡ªåŠ¨åŒ–è¿ç»´ï¼šAnsibleã€SaltStack
        - çˆ¬è™«å¼€å‘ï¼šScrapyã€BeautifulSoup
        """,
        """
        ç¬¬å››éƒ¨åˆ†ï¼šå­¦ä¹ è·¯å¾„
        1. åŸºç¡€è¯­æ³•ï¼šå˜é‡ã€æ•°æ®ç±»å‹ã€æ§åˆ¶æµ
        2. å‡½æ•°ä¸æ¨¡å—ï¼šå‡½æ•°å®šä¹‰ã€æ¨¡å—å¯¼å…¥
        3. é¢å‘å¯¹è±¡ï¼šç±»ã€ç»§æ‰¿ã€å¤šæ€
        4. æ ‡å‡†åº“ï¼šæ–‡ä»¶æ“ä½œã€ç½‘ç»œç¼–ç¨‹
        5. é«˜çº§ç‰¹æ€§ï¼šè£…é¥°å™¨ã€ç”Ÿæˆå™¨ã€å¼‚æ­¥ç¼–ç¨‹
        """,
        """
        ç¬¬äº”éƒ¨åˆ†ï¼šæœ€ä½³å®è·µ
        1. éµå¾ªPEP 8ä»£ç è§„èŒƒ
        2. ç¼–å†™å•å…ƒæµ‹è¯•
        3. ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒç®¡ç†ä¾èµ–
        4. æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²
        5. è¿›è¡Œä»£ç å®¡æŸ¥
        """
    ]
    
    analysis_prompts = [
        "è¯·æ€»ç»“ç¬¬ä¸€éƒ¨åˆ†çš„æ ¸å¿ƒå†…å®¹",
        "ç¬¬äºŒéƒ¨åˆ†æåˆ°äº†å“ªäº›é‡è¦ç‰¹æ€§ï¼Ÿ",
        "Pythonä¸»è¦åº”ç”¨åœ¨å“ªäº›é¢†åŸŸï¼Ÿ",
        "å­¦ä¹ Pythonåº”è¯¥éµå¾ªä»€ä¹ˆè·¯å¾„ï¼Ÿ",
        "æœ‰ä»€ä¹ˆæœ€ä½³å®è·µå»ºè®®ï¼Ÿ"
    ]
    
    for i, (chunk, prompt) in enumerate(zip(document_chunks, analysis_prompts), 1):
        print(f"\n[æ–‡æ¡£åˆ†æ®µ {i}]")
        
        # æ·»åŠ æ–‡æ¡£å†…å®¹
        doc_conversation.add_message(
            role="user",
            content=f"æ–‡æ¡£å†…å®¹ï¼š{chunk}\n\n{prompt}",
            important=(i == 1 or i == 3)  # æ ‡è®°ç¬¬1å’Œç¬¬3æ®µä¸ºé‡è¦
        )
        
        # è·å–åˆ†æç»“æœ
        response = await llm.chat_with_history(
            conversation=doc_conversation,
            user_message="",  # å·²ç»åœ¨ä¸Šé¢æ·»åŠ äº†
            temperature=0.3
        )
        
        print(f"ğŸ“„ å¤„ç†æ–‡æ¡£åˆ†æ®µ {i}...")
        print(f"ğŸ¤– åˆ†æç»“æœ: {response.content[:100]}...")
        
        # æ˜¾ç¤ºå‹ç¼©ç»Ÿè®¡
        stats = doc_conversation.get_compression_stats()
        print(f"ğŸ“Š ç»Ÿè®¡: æ´»è·ƒ {stats['active_messages']}, å½’æ¡£ {stats['archived_messages']}")
        
        if stats['total_compressions'] > 0:
            print(f"ğŸ”„ å·²è§¦å‘ {stats['total_compressions']} æ¬¡è‡ªåŠ¨å‹ç¼©ï¼ˆé™é»˜ï¼‰")
    
    # æ–‡æ¡£å¤„ç†å®Œæˆï¼Œå¯¼å‡ºå…³é”®ä¿¡æ¯
    print("\n" + "-" * 60)
    print("æ–‡æ¡£å¤„ç†å®Œæˆï¼Œå¯¼å‡ºå…³é”®ä¿¡æ¯...")
    print("-" * 60)
    
    # æ–¹æ³•1ï¼šå¯¼å‡ºå…³é”®ä¿¡æ¯ï¼ˆæ ¹æ® mode è‡ªåŠ¨é€‰æ‹©ç­–ç•¥ï¼‰
    important_data = doc_conversation.export_important()
    
    print(f"\nğŸ“Š å¯¼å‡ºå…³é”®ä¿¡æ¯ï¼ˆDOCUMENT æ¨¡å¼ï¼‰:")
    print(f"  - æ¨¡å¼: {important_data['mode']}")
    print(f"  - æ€»æ¶ˆæ¯æ•°: {important_data['total_messages']}")
    print(f"  - LLM åˆ†ææ¬¡æ•°: {important_data['analysis_count']}")
    
    print(f"\nğŸ¤– LLM åˆ†æç»“æœ:")
    for i, analysis in enumerate(important_data['export_content']['llm_analysis'][:3], 1):
        print(f"  {i}. {analysis['content'][:60]}...")
    
    print(f"\nğŸ“„ é‡è¦è¾“å…¥ç‰‡æ®µ:")
    for i, inp in enumerate(important_data['export_content']['important_inputs'][:2], 1):
        print(f"  {i}. {inp['content'][:60]}...")
    
    # æ–¹æ³•2ï¼šå¯¼å‡ºæ‰€æœ‰ä¿¡æ¯ï¼ˆåŒ…æ‹¬å½’æ¡£ï¼‰
    # all_data = doc_conversation.export_all()
    
    return important_data


async def demo_graph_export_format():
    """æ¼”ç¤ºå¯¼å‡ºæ ¼å¼"""
    print("\n" + "=" * 60)
    print("ğŸ“Š å¯¼å‡ºæ ¼å¼æ¼”ç¤º")
    print("=" * 60)
    
    print("\nâœ¨ SESSION æ¨¡å¼å¯¼å‡ºæ ¼å¼ï¼ˆç”¨æˆ·å¯¹è¯ï¼‰:")
    print("""
    {
        "mode": "session",
        "total_conversations": 20,           // æ€»å¯¹è¯æ•°
        "important_count": 5,                // é‡è¦æ¶ˆæ¯æ•°
        "export_content": [
            {
                "role": "user",
                "content": "è®°ä½ï¼šæˆ‘çš„ç”Ÿæ—¥æ˜¯1990-01-01",
                "timestamp": "2024-01-01T10:00:00",
                "important": true              // æ ‡è®°ä¸ºé‡è¦
            },
            {
                "role": "assistant",
                "content": "å¥½çš„ï¼Œæˆ‘å·²ç»è®°ä½äº†æ‚¨çš„ç”Ÿæ—¥...",
                "timestamp": "2024-01-01T10:00:05",
                "important": false
            },
            // ... æœ€è¿‘çš„5æ¡å¯¹è¯
        ]
    }
    
    ğŸ’¡ è¯´æ˜ï¼š
    - å¯¼å‡ºæ‰€æœ‰æ ‡è®°ä¸º important=True çš„æ¶ˆæ¯
    - é™„åŠ æœ€è¿‘çš„ 5 æ¡å¯¹è¯ï¼ˆä¿æŒä¸Šä¸‹æ–‡ï¼‰
    - è‡ªåŠ¨å»é‡
    - é€‚åˆå­˜å…¥å›¾è°±ï¼Œå»ºç«‹ç”¨æˆ·ç”»åƒå’Œå¯¹è¯å…³ç³»
    """)
    
    print("\nğŸ“„ DOCUMENT æ¨¡å¼å¯¼å‡ºæ ¼å¼ï¼ˆæ–‡æ¡£å¤„ç†ï¼‰:")
    print("""
    {
        "mode": "document",
        "total_messages": 50,                // æ€»æ¶ˆæ¯æ•°ï¼ˆå«å‹ç¼©çš„ï¼‰
        "analysis_count": 10,                // LLM åˆ†ææ¬¡æ•°
        "export_content": {
            "llm_analysis": [                 // LLM çš„åˆ†æç»“æœ
                {
                    "content": "æ–‡æ¡£æ ¸å¿ƒè§‚ç‚¹ï¼šæœ¬æ–‡è®¨è®ºäº†...",
                    "timestamp": "2024-01-01T10:05:00"
                },
                {
                    "content": "å…³é”®ä¿¡æ¯ï¼šä½œè€…è®¤ä¸º...",
                    "timestamp": "2024-01-01T10:06:00"
                }
                // ... æ›´å¤šåˆ†æç»“æœ
            ],
            "important_inputs": [             // æ ‡è®°ä¸ºé‡è¦çš„åŸå§‹è¾“å…¥
                {
                    "content": "PDFç¬¬ä¸€ç« èŠ‚å†…å®¹...ï¼ˆå‰200å­—ç¬¦ï¼‰",
                    "timestamp": "2024-01-01T10:00:00"
                }
                // ... æ›´å¤šé‡è¦è¾“å…¥ç‰‡æ®µ
            ]
        }
    }
    
    ğŸ’¡ è¯´æ˜ï¼š
    - llm_analysis: æå–æ‰€æœ‰ assistant çš„å›å¤ï¼ˆå¤§æ¨¡å‹è§£æç»“æœï¼‰
    - important_inputs: æå–æ ‡è®°ä¸ºé‡è¦çš„ç”¨æˆ·è¾“å…¥ï¼ˆåŸå§‹æ–‡æ¡£å…³é”®éƒ¨åˆ†ï¼‰
    - å†…å®¹è¶…è¿‡200å­—ç¬¦ä¼šè¢«æˆªæ–­ï¼ˆåŠ ...ï¼‰
    - é€‚åˆå­˜å…¥å›¾è°±ï¼Œå»ºç«‹æ–‡æ¡£å®ä½“å’Œå…³é”®ä¿¡æ¯
    """)


async def demo_comparison():
    """æ¼”ç¤ºä¸¤ç§æ¨¡å¼çš„å¯¹æ¯”"""
    print("\n" + "=" * 60)
    print("ä¸¤ç§æ¨¡å¼å¯¹æ¯”")
    print("=" * 60)
    
    comparison_table = """
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     ç‰¹æ€§        â”‚   SESSION æ¨¡å¼        â”‚   DOCUMENT æ¨¡å¼       â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ ä½¿ç”¨åœºæ™¯        â”‚ ç”¨æˆ·å¤šè½®å¯¹è¯          â”‚ é•¿æ–‡æœ¬å¤„ç†            â”‚
    â”‚ å‹ç¼©ç­–ç•¥        â”‚ å°½é‡ä¿ç•™å®Œæ•´å†å²      â”‚ è‡ªåŠ¨é™é»˜å‹ç¼©          â”‚
    â”‚ å¯¼å‡ºæ—¶æœº        â”‚ å¯¹è¯ç»“æŸæ—¶            â”‚ å¤„ç†å®Œæˆæ—¶            â”‚
    â”‚ å¯¼å‡ºå†…å®¹        â”‚ é‡è¦æ¶ˆæ¯+æœ€è¿‘å¯¹è¯     â”‚ LLMåˆ†æç»“æœ          â”‚
    â”‚ é‡è¦æ€§æ ‡è®°      â”‚ æ”¯æŒ                  â”‚ æ”¯æŒ                  â”‚
    â”‚ å½’æ¡£æœºåˆ¶        â”‚ æ”¯æŒ                  â”‚ æ”¯æŒ                  â”‚
    â”‚ æ—¥å¿—çº§åˆ«        â”‚ WARNINGï¼ˆå‹ç¼©æ—¶ï¼‰     â”‚ INFOï¼ˆé™é»˜å‹ç¼©ï¼‰      â”‚
    â”‚ å…¸å‹ç”¨é€”        â”‚ èŠå¤©ã€é—®ç­”            â”‚ PDFåˆ†æã€æ–‡æ¡£è§£æ     â”‚
    â”‚ å›¾è°±å­˜å‚¨        â”‚ å¯¹è¯å…³ç³»ã€ç”¨æˆ·ç”»åƒ    â”‚ æ–‡æ¡£å®ä½“ã€å…³é”®ä¿¡æ¯    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """
    
    print(comparison_table)
    
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("  1. SESSION æ¨¡å¼ï¼ˆç”¨æˆ·å¯¹è¯ï¼‰ï¼š")
    print("     - ç”¨äºç”¨æˆ·æ—¥å¸¸å¯¹è¯")
    print("     - å¯¹è¯ç»“æŸæ—¶è°ƒç”¨ export_important() æˆ– clear_and_export()")
    print("     - å¯¼å‡ºå†…å®¹ï¼šæ ‡è®°ä¸º important çš„æ¶ˆæ¯ + æœ€è¿‘5æ¡å¯¹è¯")
    print("     - å¯å­˜å…¥å›¾è°±å»ºç«‹ç”¨æˆ·ç”»åƒã€å¯¹è¯å…³ç³»")
    print("")
    print("  2. DOCUMENT æ¨¡å¼ï¼ˆæ–‡æ¡£å¤„ç†ï¼‰ï¼š")
    print("     - ç”¨äºå¤„ç†ä¸Šä¼ çš„æ–‡æ¡£ï¼ˆPDFã€TXTç­‰ï¼‰")
    print("     - å¤„ç†å®Œæˆåè°ƒç”¨ export_important()")
    print("     - å¯¼å‡ºå†…å®¹ï¼šLLM çš„åˆ†æç»“æœï¼ˆassistant å›å¤ï¼‰")
    print("     - å¯å­˜å…¥å›¾è°±å»ºç«‹æ–‡æ¡£å®ä½“ã€å…³é”®ä¿¡æ¯")
    print("")
    print("  3. å…±åŒç‚¹ï¼š")
    print("     - éƒ½ä¼šå½’æ¡£è¢«å‹ç¼©çš„æ¶ˆæ¯ï¼ˆä¿¡æ¯ä¸ä¸¢å¤±ï¼‰")
    print("     - éƒ½æ”¯æŒå¯¼å‡ºå…³é”®ä¿¡æ¯ï¼ˆexport_importantï¼‰")
    print("     - éƒ½æ”¯æŒå¯¼å‡ºæ‰€æœ‰ä¿¡æ¯ï¼ˆexport_allï¼‰")
    print("     - éƒ½æ”¯æŒé‡è¦æ€§æ ‡è®°ï¼ˆimportant=Trueï¼‰")


async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("AME åŒæ¨¡å¼ä¸Šä¸‹æ–‡ç®¡ç†ç¤ºä¾‹")
    print("=" * 60)
    
    # è¿è¡Œæ¼”ç¤º
    await demo_session_mode()
    await demo_document_mode()
    await demo_graph_export_format()
    await demo_comparison()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("âœ¨ æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)
    
    print("\nğŸ“– æ ¸å¿ƒåŠŸèƒ½:")
    print("  1. SESSION æ¨¡å¼ - ç”¨æˆ·å¯¹è¯ï¼Œå¯¼å‡ºé‡è¦ä¿¡æ¯")
    print("  2. DOCUMENT æ¨¡å¼ - æ–‡æ¡£å¤„ç†ï¼Œå¯¼å‡º LLM åˆ†æç»“æœ")
    print("  3. é‡è¦æ€§æ ‡è®° - important=True ä¼˜å…ˆä¿ç•™")
    print("  4. å½’æ¡£æœºåˆ¶ - å‹ç¼©çš„æ¶ˆæ¯è‡ªåŠ¨å½’æ¡£")
    print("  5. å¯¼å‡ºèƒ½åŠ› - export_important() / export_all() / clear_and_export()")
    print("  6. ç»Ÿè®¡ä¿¡æ¯ - get_compression_stats()")
    
    print("\nğŸ’¾ å¯¼å‡ºè¯´æ˜:")
    print("  export_important() - å¯¼å‡ºå…³é”®ä¿¡æ¯ï¼ˆæ ¹æ® mode è‡ªåŠ¨é€‰æ‹©ç­–ç•¥ï¼‰")
    print("    SESSION: é‡è¦æ¶ˆæ¯ + æœ€è¿‘5æ¡å¯¹è¯")
    print("    DOCUMENT: LLM åˆ†æç»“æœ + é‡è¦è¾“å…¥ç‰‡æ®µ")
    print("  ")
    print("  export_all() - å¯¼å‡ºæ‰€æœ‰æ¶ˆæ¯ï¼ˆåŒ…æ‹¬å½’æ¡£ï¼‰")
    print("    é€‚ç”¨äºéœ€è¦å®Œæ•´å†å²æˆ–æ•°æ®å¤‡ä»½")
    print("  ")
    print("  clear_and_export() - æ¸…ç©ºå¹¶å¯¼å‡ºå…³é”®ä¿¡æ¯")
    print("    å¯¹è¯/æ–‡æ¡£å¤„ç†ç»“æŸæ—¶è°ƒç”¨")


if __name__ == "__main__":
    asyncio.run(main())
